{
    "content/configuration/client-settings.html":  {
                                                       "href":  "content/configuration/client-settings.html",
                                                       "title":  "Client settings",
                                                       "keywords":  "Client settings The client settings configuration is automatically generated when a new data source is added. If you experience problems with timeouts or when OPC UA limits are exceeded in terms of browse or subscription operation, you can change the client settings configuration. Generate default OPC UA client settings configuration file If a valid data source exists, the adapter is running, and you do not want to configure OPC UA client settings, you can choose to generate a default OPC UA client settings file. Complete the following steps to generate the default client settings file: Add an OPC UA adapter with a unique ComponentId . For more information, see System components configuration . Configure a valid OPC UA data source. For more information, see AVEVA Adapter for OPC UA data source configuration . Once you complete these steps, a default OPC UA client settings configuration file generates in the configuration directory for the corresponding platform. The following are example locations of the file created. In this example, the ComponentId of the OPC UA component is OpcUa1: Windows: %programdata%\\OSIsoft\\Adapters\\OpcUa\\Configuration\\OpcUa1_ClientSettings.json Linux: /usr/share/OSIsoft/Adapters/OpcUa/Configuration/OpcUa1_ClientSettings.json  usr share OSIsoft Adapters OpcUa Configuration OpcUa1_ClientSettings.json Configure OPC UA client settings Complete the following steps to configure OPC UA client settings. Use the PUT method in conjunction with the api/v1/configuration/\u003cComponentId\u003e/ClientSettings api v1 configuration \u003cComponentId\u003e ClientSettings REST endpoint to initialize the configuration. Use a text editor to create an empty text file. Copy and paste an example configuration for OPC UA client settings into the file. For sample JSON, see OPC UA client settings example . Update the example JSON parameters for your environment. For a table of all available parameters, see OPC UA client settings parameters . Save the file. For example, as ConfigureClientSettings.json . Open a command line session. Change directory to the location of ConfigureClientSettings.json . Enter the following cURL command (which uses the PUT method) to initialize the client settings configuration. curl -d \"@ConfigureClientSettings.json\" -H \"Content-Type: application/json\" application json\" -X PUT \"http://localhost:5590/api/v1/configuration/OpcUa1/ClientSettings\" \"http:  localhost:5590 api v1 configuration OpcUa1 ClientSettings\" Notes: If you installed the adapter to listen on a non-default port, update 5590 to the port number in use. If you use a component ID other than OpcUa1 , update the endpoint with your chosen component ID. For a list of other REST operations you can perform, like updating or deleting a client settings configuration, see REST URLs . OPC UA client settings schema The full schema definition for the OPC UA client settings configuration is in the OpcUa_ClientSettings_schema.json file located in one of the following folders: Windows: %ProgramFiles%\\OSIsoft\\Adapters\\OpcUa\\Schemas Linux: /opt/OSIsoft/Adapters/OpcUa/Schemas  opt OSIsoft Adapters OpcUa Schemas OPC UA client settings parameters The following parameters are available for configuring OPC UA client settings: Note : All intervals, delays, and timeouts require the string to be formatted like this: [d:]h:mm:ss[.FFFFFFF] where the items in brackets are optional. d = days, h = hours, mm = minutes, ss = seconds, F = fractional portion of a second. Example: \"05:07:10:40.150\" for 5 days, 7 hours, 10 minutes, 40 seconds, and .150 seconds. Parameter Required Type Description maxBrowseReferencesToReturn Optional integer Maximum number of references returned from browse call. Minimum value: 0 Maximum value: 4294967295 Default value: 0 browseBlockSize Optional integer Maximum number of nodes to browse in one call. Minimum value: 1 Maximum value: 4294967295 Default value: 10 readBlockSize Optional integer Maximum number of variables to read in one call. Minimum value: 0 Maximum value: 4294967295 Default value: 1000 reconnectDelay Optional TimeSpan Delay between reconnection attempts. *Does not apply to the initial connection, only reconnections. Allowed value: cannot be negative Default value: 0:00:30 recreateSubscriptionDelay Optional TimeSpan Delay between successful reconnection and subsequent subscription recreation. * Allowed value: cannot be negative Default value: 0:00:10 sessionRequestTimeout Optional TimeSpan Default request timeout. * Allowed value: greater than 00:00:05 Default value: 0:02:00 connectionTimeout Optional TimeSpan Connection timeout. * Allowed value: greater than 00:00:05 Default value: 0:00:30 sessionAllowInsecureCredentials Optional boolean When set to true credentials can be communicated over unencrypted channel. Allowed value: true or false Default value: false sessionMaxOperationsPerRequest Optional integer Default maximum operation per request. Minimum value: 0 Maximum value: 4294967295 Default value: 1000 browseTimeout Optional TimeSpan Browse operation timeout. * Allowed value: greater than 00:00:05 Default value: 0:01:00 readTimeout Optional TimeSpan Read operation timeout. * Allowed value: greater than 00:00:05 Default value: 0:00:30 maxMonitoredItemsPerCall Optional integer Maximum number of monitored items that can be added to subscription in one call. Minimum value: 1 Maximum value: 4294967295 Default value: 1000 maxNotificationsPerPublish Optional integer Maximum notification messages in one publish message. Minimum value: 0 Maximum value: 4294967295 Default value: 0 publishingInterval Optional TimeSpan Publishing interval of the subscription. * Allowed value: cannot be negative Default value: 0:00:01 createMonitoredItemsTimeout Optional TimeSpan Create monitored items timeout. * Allowed value: greater than 00:00:05 Default value: 0:00:30 samplingInterval Optional TimeSpan Monitored item sampling interval. * Allowed value: cannot be negative Default value: 0:00:00:5 monitoredItemDataChangeTrigger Optional string Determines on what conditions a subscription sends new values to the adapter. Allowed values: Status , StatusValue , StatusValueTimestamp Default value: StatusValue monitoredItemQueueSize Optional integer Monitored item queue size. Minimum value: 1 Maximum value: 4294967295 Default value: 2 maxInternalQueueSize Optional integer Maximum number of items that can be in the adapter internal queue. Minimum value: 1000 Maximum value: 2147483647 Default value: 500000 HistoryReadBlockSize Optional integer Maximum number of nodes for history to read in one call. Minimum value: 1 Maximum value: 4294967295 Default value: 10 HistoryReadTimeout Optional TimeSpan History read operation timeout. * Allowed value: greater than 00:00:05 Default value: 0:01:00 * Note: You can also specify timespans as numbers in seconds. For example, \"reconnectDelay\": 25 specifies 25 seconds, or \"reconnectDelay\": 125.5 specifies 2 minutes and 5.5 seconds. OPC UA client settings example { \"MaxBrowseReferencesToReturn\": 0, \"BrowseBlockSize\": 10, \"ReconnectDelay\": \"0:00:30\", \"RecreateSubscriptionDelay\": \"0:00:10\", \"ReadBlockSize\": 1000, \"SessionRequestTimeout\": \"0:02:00\", \"ConnectionTimeout\": \"0:00:30\", \"ReadTimeout\": \"0:00:30\", \"SessionAllowInsecureCredentials\": false, \"SessionMaxOperationsPerRequest\": 1000, \"BrowseTimeout\": \"0:01:00\", \"MaxMonitoredItemsPerCall\": 1000, \"MaxNotificationsPerPublish\": 0, \"PublishingInterval\": \"0:00:01\", \"CreateMonitoredItemsTimeout\": \"0:00:30\", \"MonitoredItemDataChangeTrigger\": \"StatusValue\", \"SamplingInterval\": \"0:00:00.5\", \"MonitoredItemQueueSize\": 2, \"MaxInternalQueueSize\": 500000, \"HistoryReadBlockSize\": 10, \"HistoryReadTimeout\": \"0:01:00\" } REST URLs Relative URL HTTP verb Action api/v1/configuration/\u003cComponentId\u003e/ClientSettings api v1 configuration \u003cComponentId\u003e ClientSettings GET Retrieves the OPC UA client settings configuration. api/v1/configuration/\u003cComponentId\u003e/ClientSettings api v1 configuration \u003cComponentId\u003e ClientSettings PUT Configures or updates the OPC UA client settings configuration. api/v1/configuration/\u003cComponentId\u003e/ClientSettings api v1 configuration \u003cComponentId\u003e ClientSettings DELETE Deletes the OPC UA client settings configuration. api/v1/configuration/\u003cComponentId\u003e/ClientSettings api v1 configuration \u003cComponentId\u003e ClientSettings PATCH Allows partial updating of configured client settings fields. Note: Replace \u003cComponentId\u003e with the Id of your OPC UA component, for example OpcUa1."
                                                   },
    "content/configuration/configuration.html":  {
                                                     "href":  "content/configuration/configuration.html",
                                                     "title":  "Configuration",
                                                     "keywords":  "Configuration AVEVA Adapter for OPC UA enables you to configure data source and data selection. The adapter also provides the ability to configure security and to generate a data selection file instead of manual configuration. The examples in the configuration topics use curl , a commonly available tool on both Windows and Linux. The adapter can be configured with any programming language or tool that supports making REST calls, or with the EdgeCmd utility. For more information, see the EdgeCmd utility documentation . To validate configurations, you can perform data retrieval (GET commands) using a browser, if available on your device. For more information on AVEVA Adapter configuration tools, see Configuration tools . Quick start These steps guide you through setup of each configuration file available for AVEVA Adapter for OPC UA. As you complete each step, perform each required configuration to establish a data flow from a data source to one or more endpoints. Some configurations are optional. Important: If you want to complete the optional configurations, complete those tasks before the required tasks. Configure one or several OPC UA system components.See System components . Configure an OPC UA data source for each OPC UA device.See Data source . Optional : Configure client settings. See Client settings . Optional : Perform data source discovery. See Discovery . Configure an OPC UA data selection for each OPC UA data source.See Data selection . Optional : Configure data filters, security, diagnostics and metadata, buffering, and logging.See the following topics: Data filters Security Diagnostics and metadata Buffering Logging Configure one or several egress and health endpoints.See Egress endpoints and Health endpoints ."
                                                 },
    "content/configuration/configuration-examples.html":  {
                                                              "href":  "content/configuration/configuration-examples.html",
                                                              "title":  "Configuration examples",
                                                              "keywords":  "Configuration examples The following tables provide examples for all configurations available for AVEVA Adapter for OPC UA. Note: The examples in this topic are using the default port number 5590 . If you selected a different port number, replace it with that value. System components configuration with two OPC UA adapter instances [ { \"componentId\": \"OpcUa1\", \"componentType\": \"OpcUa\" }, { \"componentId\": \"OpcUa2\", \"componentType\": \"OpcUa\" }, { \"componentId\": \"OmfEgress\", \"componentType\": \"OmfEgress\" } ] OPC UA adapter configuration { \"OpcUa1\": { \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 }, \"DataSource\": { \"endpointUrl\": \"opc.tcp://OPCUAServerEndpoint/OPCUA/Server\", \"opc.tcp:  OPCUAServerEndpoint OPCUA Server\", \"useSecureConnection\": false, \"userName\": null, \"password\": null, \"incomingTimestamp\": \"Source\", \"streamIdPrefix\": \"OPC_Prefix_\", \"defaultStreamIdPattern\": \"{NamespaceIndex}.{Identifier}\", \"dataCollectionMode\": \"CurrentWithBackfill\", \"serverFailoverEnabled\": false }, \"DataSelection\": [ { \"selected\": true, \"name\": \"Sawtooth\", \"nodeId\": \"ns=3;s=Sawtooth\", \"streamId\": \"SawtoothStream\", \"dataFilterId\": null } ] }, \"System\": { \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 }, \"HealthEndpoints\": [ ], \"Diagnostics\": { \"enableDiagnostics\": true }, \"Components\": [ { \"componentId\": \"Egress\", \"componentType\": \"OmfEgress\" }, { \"componentId\": \"OpcUa1\", \"componentType\": \"OpcUa\" } ], \"Buffering\": { \"bufferLocation\": \"C:/ProgramData/OSIsoft/Adapters/OpcUa/Buffers\", \"C: ProgramData OSIsoft Adapters OpcUa Buffers\", \"maxBufferSizeMB\": -1, \"enableBuffering\": true } }, \"OmfEgress\": { \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 }, \"DataEndpoints\": [ { \"id\": \"WebAPI EndPoint\", \"endpoint\": \"https://PIWEBAPIServer/piwebapi/omf\", \"https:  PIWEBAPIServer piwebapi omf\", \"userName\": \"USERNAME\", \"password\": \"PASSWORD\" }, { \"id\": \"AVEVA Data Hub Endpoint\", \"endpoint\": \"https://AVEVA \"https:  AVEVA Data HubEndpoint/omf\", HubEndpoint omf\", \"clientId\": \"CLIENTID\", \"clientSecret\": \"CLIENTSECRET\" } { \"id\": \"EDS\", \"endpoint\": \"http://localhost:/api/v1/tenants/default/namespaces/default/omf\", \"http:  localhost: api v1 tenants default namespaces default omf\", \"clientId\": \"eds\", \"clientSecret\": \"eds\" } ] } } Data source configuration The following are representations of minimal and complete data source configurations of OPC UA adapter. Minimal data source configuration { \"endpointUrl\": \"opc.tcp://\u003cIP-Address\u003e:\u003cPort\u003e/\u003cTestOPCUAServer\u003e\" \"opc.tcp:  \u003cIP-Address\u003e:\u003cPort\u003e \u003cTestOPCUAServer\u003e\" } Complete data source configuration { \"endpointUrl\": \"opc.tcp://\u003cIP-Address\u003e:\u003cPort\u003e/\u003cTestOPCUAServer\u003e\", \"opc.tcp:  \u003cIP-Address\u003e:\u003cPort\u003e \u003cTestOPCUAServer\u003e\", \"useSecureConnection\": true, \"userName\": null, \"password\": null, \"incomingTimestamp\": \"Source\", \"streamIdPrefix\": null, \"defaultStreamIdPattern\": \"{NamespaceIndex}.{Identifier}\" } Client settings configuration { \"maxBrowseReferencesToReturn\": 0, \"browseBlockSize\": 10, \"readBlockSize\": 1000, \"reconnectDelay\": \"0:00:30\", \"recreateSubscriptionDelay\": \"0:00:05\", \"sessionRequestTimeout\": \"0:02:00\", \"connectionTimeout\": \"0:00:30\", \"sessionAllowInsecureCredentials\": false, \"sessionMaxOperationsPerRequest\": 1000, \"browseTimeout\": \"0:01:00\", \"readTimeout\": \"0:00:30\", \"maxMonitoredItemsPerCall\": 1000, \"maxNotificationsPerPublish\": 0, \"publishingInterval\": \"0:00:01\", \"createMonitoredItemsTimeout\": \"0:00:30\", \"samplingInterval\": \"0:00:00.5\", \"monitoredItemQueueSize\": 2, \"maxInternalQueueSize\": 500000 } Data selection configuration The following are representations of minimal and complete data selection configurations of OPC UA adapter. Minimal data selection configuration [ { \"nodeId\": \"ns=5;s=Random1\" }, { \"nodeId\": \"ns=5;s=Sawtooth1\" }, { \"nodeId\": \"ns=5;s=Sinusoid1\" } ] Complete data selection configuration [ { \"selected\": true, \"name\": \"CustomStreamName\", \"nodeId\": \"ns=5;s=Random1\", \"streamId\": \"CustomStreamName\", \"dataFilterId\": \"DuplicateData\" }, { \"selected\": false, \"name\": null, \"nodeId\": \"ns=5;s=Sawtooth1\", \"streamId\": null, \"dataFilterId\": \"DuplicateData\" }, { \"selected\": true, \"name\": \"5.Sinusoid1\", \"nodeId\": \"ns=5;s=Sinusoid1\", \"streamId\": null, \"dataFilterId\": null } ]"
                                                          },
    "content/configuration/data-selection.html":  {
                                                      "href":  "content/configuration/data-selection.html",
                                                      "title":  "Data selection",
                                                      "keywords":  "Data selection In addition to the data source configuration, you need to provide a data selection configuration to specify the data you want the adapter to collect from the data sources. OPC UA data from OPC UA items is read through subscriptions (unsolicited reads). You can decide to create the data selection configuration file yourself or you can perform a data source discovery to find available items. For more information, see Discovery . Configure OPC UA data selection Complete the following steps to configure an OPC UA data selection. Use the PUT method in conjunction with the api/v1/configuration/\u003cComponentId\u003e/DataSelection api v1 configuration \u003cComponentId\u003e DataSelection REST endpoint to initialize the configuration. Use a text editor to create an empty text file. Copy and paste an example configuration for an OPC UA data selection into the file. For sample JSON, see OPC UA data selection examples . Update the example JSON parameters for your environment. For a table of all available parameters, see OPC UA data selection parameters . Save the file. For example, as ConfigureDataSelection.json . Open a command line session. Change directory to the location of ConfigureDataSelection.json . Enter the following curl command (which uses the PUT method) to initialize the data selection configuration. curl -d \"@ConfigureDataSelection.json\" -H \"Content-Type: application/json\" application json\" -X PUT \"http://localhost:5590/api/v1/configuration/OpcUa1/DataSelection\" \"http:  localhost:5590 api v1 configuration OpcUa1 DataSelection\" Notes: If you installed the adapter to listen on a non-default port, update 5590 to the port number in use. If you use a component ID other than OpcUa1 , update the endpoint with your chosen component ID. For a list of other REST operations you can perform, like updating or deleting a data selection configuration, see REST URLs . OPC UA data selection schema The full schema definition for the OPC UA data selection configuration is in the OpcUa_DataSelection_schema.json file located in one of the following folders: Windows: %ProgramFiles%\\OSIsoft\\Adapters\\OpcUa\\Schemas Linux: /opt/OSIsoft/Adapters/OpcUa/Schemas  opt OSIsoft Adapters OpcUa Schemas OPC UA data selection parameters The following parameters are available for configuring an OPC UA data selection: Parameter Required Type Description selected Optional boolean Use this field to select or clear a measurement. To select an item, set to true. To remove an item, leave the field empty or set to false. Allowed value: true or false Default value: true name Optional string Name of the data item collected from the data source. Default value: null results in StreamId value being used also as a Name nodeId Required string The NodeId of the variable.Examples \"ns=5;AString\"``\"ns=2;i=203\"``\"ns=\u003cNamespaceIndex\u003e;\u003cIdentifierType\u003e=\u003cIdentifer\u003e\" streamID Optional string The custom stream ID used to create the streams. If not specified, the adapter will generate a default stream ID based on the measurement configuration. The StreamId serves as the unique identifier of a data selection item. A properly configured custom stream ID follows these rules:Is not case-sensitive.Can contain spaces.Cannot start with two underscores (\"__\").Can contain a maximum of 2000 characters.Cannot use the following characters: /   : ? # [ ] @ ! $ \u0026 \u0027 ( ) \\ * + , ; = % \u003c \u003e |Cannot start or end with a period.Cannot contain consecutive periods.Cannot consist of only periods.For more information on how the adapter encodes special characters in the StreamId , see Egress endpoints . dataFilterId Optional string Enables data filtering for this data selection item if the ID of a data filter is specified. Note: If the specified DataFilterId does not exist, unfiltered data is sent until that DataFilterId is created. OPC UA data selection examples The following are examples of valid OPC UA data selection configurations: Minimal data selection configuration [ { \"nodeId\": \"ns=5;s=Random1\" }, { \"nodeId\": \"ns=5;s=Sawtooth1\" }, { \"nodeId\": \"ns=5;s=Sinusoid1\" } ] Complete data selection configuration [ { \"selected\": true, \"name\": \"CustomStreamName\", \"nodeId\": \"ns=5;s=Random1\", \"streamId\": \"CustomStreamName\", \"dataFilterId\": \"DuplicateData\" }, { \"selected\": false, \"name\": null, \"nodeId\": \"ns=5;s=Sawtooth1\", \"streamId\": null, \"dataFilterId\": \"DuplicateData\" }, { \"selected\": true, \"name\": \"5.Sinusoid1\", \"nodeId\": \"ns=5;s=Sinusoid1\", \"streamId\": null, \"dataFilterId\": null } ] REST URLs Relative URL HTTP verb Action api/v1/configuration/\u003cComponentId\u003e/DataSelection api v1 configuration \u003cComponentId\u003e DataSelection GET Retrieves the data selection configuration, including all data selection items. api/v1/configuration/\u003cComponentId\u003e/DataSelection api v1 configuration \u003cComponentId\u003e DataSelection PUT Configures or updates the data selection configuration. The adapter starts collecting data for each data selection item when the following conditions are met: ??? The data selection configuration PUT request is received. ??? A data source configuration is active. api/v1/configuration/\u003cComponentId\u003e/DataSelection api v1 configuration \u003cComponentId\u003e DataSelection DELETE Deletes the active data selection configuration. The adapter stops collecting data. api/v1/configuration/\u003cComponentId\u003e/DataSelection api v1 configuration \u003cComponentId\u003e DataSelection PATCH Allows partial updates of configured data selection items. Note: The request must be an array containing one or more data selection items. Each item in the array must include its StreamId . api/v1/configuration/\u003cComponentId\u003e/DataSelection/\u003cStreamId\u003e api v1 configuration \u003cComponentId\u003e DataSelection \u003cStreamId\u003e PUT Updates or creates a new data selection item by StreamId . For new items, the adapter starts collecting data after the request is received. api/v1/configuration/\u003cComponentId\u003e/DataSelection/\u003cStreamId\u003e api v1 configuration \u003cComponentId\u003e DataSelection \u003cStreamId\u003e DELETE Deletes a data selection item from the configuration by StreamId . The adapter stops collecting data for the deleted item. Note: Replace \u003cComponentId\u003e with the Id of your OPC UA component, for example OpcUa1 ."
                                                  },
    "content/configuration/data-source.html":  {
                                                   "href":  "content/configuration/data-source.html",
                                                   "title":  "Data source",
                                                   "keywords":  "Data source To use the adapter, you must configure the data source from which it gets data. Configure OPC UA data source Complete the following steps to configure an OPC UA data source. Use the PUT method in conjunction with the api/v1/configuration/\u003cComponentId\u003e/DataSource api v1 configuration \u003cComponentId\u003e DataSource REST endpoint to initialize the configuration. Use a text editor to create an empty text file. Copy and paste an example configuration for an OPC UA data source into the file. For sample JSON, see OPC UA data source examples . Update the example JSON parameters for your environment. For a table of all available parameters, see OPC UA data source parameters . Save the file. For example, as ConfigureDataSource.json . Open a command line session. Change directory to the location of ConfigureDataSource.json . Enter the following cURL command (which uses the PUT method) to initialize the data source configuration. curl -d \"@ConfigureDataSource.json\" -H \"Content-Type: application/json\" application json\" -X PUT \"http://localhost:5590/api/v1/configuration/OpcUa1/DataSource\" \"http:  localhost:5590 api v1 configuration OpcUa1 DataSource\" Notes: If you installed the adapter to listen on a non-default port, update 5590 to the port number in use. If you use a component ID other than OpcUa1 , update the endpoint with your chosen component ID. For a list of other REST operations you can perform, like updating or deleting a data source configuration, see REST URLs . Configure data selection. For more information, see AVEVA Adapter for OPC UA data selection configuration . OPC UA data source schema The full schema definition for the OPC UA data source configuration is in the OpcUa_DataSource_schema.json file located in one of the following folders: Windows: %ProgramFiles%\\OSIsoft\\Adapters\\OpcUa\\Schemas Linux: /opt/OSIsoft/Adapters/OpcUa/Schemas  opt OSIsoft Adapters OpcUa Schemas OPC UA data source parameters The following parameters are available for configuring an OPC UA data source: Parameter Required Type Description endpointURL Required string The endpoint URL of the OPC UA server in opc.tcp format. The following is an example of the URL format: opc.tcp://OPCServerHost:Port/OpcUa/SimulationServer opc.tcp:  OPCServerHost:Port OpcUa SimulationServer Note: If you change the EndpointURL on a configured adapter that has ComponentID_DataSelection.json file exported, you need to remove the ComponentID_DataSelection.json file from the configuration directory to trigger a new browse (export). Allowed value: well-formed opc.tcp address useSecureConnection Optional boolean When set to true, the adapter connects to a secure endpoint using OPC UA certificate exchange operation. The default is true. When set to false, the adapter connects to an unsecured endpoint of the server and certificate exchange operation is not required. Note: OSIsoft recommends setting this option to false for testing purposes only. Allowed value: true or false Default value: true userName Optional string User name for accessing the OPC UA server. Allowed value: any string Default value: null password Optional string Password for accessing the OPC UA server. Note: OSIsoft recommends using REST to configure the data source when the password must be specified because REST will encrypt the password. If you do not use REST, the plain text password will be stored on-disk. Allowed value: any string Default value: null incomingTimestamp Optional string Specifies whether the incoming timestamp is taken from the source, from the OPC UA server, or should be created by the adapter instance. Source - Default and recommended setting. The timestamp is taken from the source timestamp field. The source is what provides data for the item to the OPC UA server, such as a field device. Server - In case the OPC UA item has an invalid source timestamp field, the Server timestamp can be used. Adapter - The adapter generates a timestamp for the item upon receiving it from the OPC UA server. Allowed value: Source , Server , or Adapter Default value: Source streamIdPrefix Optional string Specifies what prefix is used for Stream IDs. The naming convention is {StreamIdPrefix}{StreamId} . An empty string means no prefix will be added to the Stream IDs and names. A null value defaults to ComponentID followed by a period.Example: OpcUa1.{NamespaceIndex}.{Identifier} Note: Every time you change the StreamIdPrefix of a configured adapter???for example, when you delete and add a data source???you need to restart the adapter for the changes to take place. New streams are created on adapter restart and pre-existing streams are no longer updated. Allowed value: any string Default value: null defaultStreamIdPattern Optional string Specifies the default StreamId pattern to use. Possible parameters: {NamespaceIndex} 1 , {Identifier} . Allowed value: any string Default value: {NamespaceIndex}.{Identifier} dataCollectionMode Optional string Specifies the data collection mode the adapter is in. The following data collection modes are available: HistoryOnly 2 - The adapter component does not get started and history recovery on-demand is enabled. For more information, see On-demand history recovery . CurrentOnly - The adapter component operates normally and on-demand history recovery is disabled. CurrentWithBackfill 2 - The adapter component operates normally, but disconnections are recorded based on device status. History recovery backfills data once device status is good . On-demand history recovery is disabled. For more information, see Automatic history recovery . Changing the mode requires a restart of the adapter component. serverFailoverEnabled Optional boolean Specifies whether to use server-side failover. Allowed value: true or false Default value: false 1 NamespaceIndex refers to the number specified in the ns keyword in the RootNodeIds parameter. 2 Historical values are collected only for OPC UA items that have the AccessLevel attribute set to HistoryRead . OPC UA data source examples The following are examples of valid OPC UA data source configurations: Minimal data source configuration { \"endpointUrl\": \"opc.tcp://\u003cIP-Address\u003e:\u003cPort\u003e/\u003cTestOPCUAServer\u003e\" \"opc.tcp:  \u003cIP-Address\u003e:\u003cPort\u003e \u003cTestOPCUAServer\u003e\" } Complete data source configuration { \"endpointUrl\": \"opc.tcp://\u003cIP-Address\u003e:\u003cPort\u003e/\u003cTestOPCUAServer\u003e\", \"opc.tcp:  \u003cIP-Address\u003e:\u003cPort\u003e \u003cTestOPCUAServer\u003e\", \"useSecureConnection\": true, \"userName\": null, \"password\": null, \"incomingTimestamp\": \"Source\", \"streamIdPrefix\": null, \"defaultStreamIdPattern\": \"{NamespaceIndex}.{Identifier}\", \"dataCollectionMode\": \"CurrentWithBackfill\", \"serverFailoverEnabled\": false } REST URLs Relative URL HTTP verb Action api/v1/configuration/\u003cComponentId\u003e/DataSource api v1 configuration \u003cComponentId\u003e DataSource GET Retrieves the data source configuration. api/v1/configuration/\u003cComponentId\u003e/DataSource api v1 configuration \u003cComponentId\u003e DataSource POST Creates the data source configuration. The adapter starts collecting data after the following conditions are met: ??? The data source configuration POST request is received. ??? A data selection configuration is active. api/v1/configuration/\u003cComponentId\u003e/DataSource api v1 configuration \u003cComponentId\u003e DataSource PUT Configures or updates the data source configuration. Overwrites any active data source configuration. If no configuration is active, the adapter starts collecting data after the following conditions are met: ??? The data source configuration PUT request is received. ??? A data selection configuration is active. api/v1/configuration/\u003cComponentId\u003e/DataSource api v1 configuration \u003cComponentId\u003e DataSource DELETE Deletes the data source configuration. After the request is received, the adapter stops collecting data. Note: Replace \u003cComponentId\u003e with the Id of your OPC UA component, for example OpcUa1 ."
                                               },
    "content/configuration/data-source-discovery.html":  {
                                                             "href":  "content/configuration/data-source-discovery.html",
                                                             "title":  "Data source discovery",
                                                             "keywords":  "Data source discovery A discovery against the data source of an OPC UA adapter allows you to specify the optional query parameter. The discovery query limits the number of objects to browse. Note: Only one discovery at a time is supported. Query string The string of the query parameter must contain string items in the following form: rootNodeIds=\u003cnodeId\u003e String item Required Description rootNodeIds Optional The node Ids that the adapter will begin browse operation from. Note: To specify multiple node IDs in the query, separate the node IDs with a comma. If rootNodeIds is not specified, the adapter initiates browse operation from the object folder. Note: A NodeId is a unique identification on the OPC UA server that consists of namespace index and identifier. Query rules The following rules apply for specifying the query string: Multiple comma-separated nodeIds are supported. The nodeId specified in the query string must be valid. RootNodeIds= must be followed by a nodeId. Empty string and all white spaces string is equivalent to no query specified. White spaces in the RooteNodeIds= section of the query are not supported Note: The data source might contain large amounts of items. Use the root nodeIds in the query string to browse only items that you need. Discovery query example The query parameter of the OPC UA component must be specified as shown in this example: RootNodeIds=ns=4;s=Boilers, ns=4;s=Pumps . Data source discovery initiation { \"id\" : \"SampleA\", \"query\" : \"RootNodeIds=ns=6;s=MyDevice\" } Data source discovery results [ { \"id\": \"PlantA\", \"query\": \"RootNodeIds=ns=6;s=MyDevice\", \"startTime\": \"2020-12-14T14:19:01.4383791-08:00\", \"endTime\": \"2020-12-14T14:19:31.8549164-08:00\", \"progress\": 30, \"itemsFound\": 700, \"newItems\": 200, \"resultUri\": \"http://127.0.0.1:5590/api/v1/Configuration/OpcUaComponentId/Discoveries/PlantA/result\", \"http:  127.0.0.1:5590 api v1 Configuration OpcUaComponentId Discoveries PlantA result\", \"autoSelect\": false, \"status\": \"Complete\", \"errors\": null } ] OPC UA discovered selection items [ { \"selected\": false, \"name\": null, \"nodeId\": \"ns=5;s=Pump.Temperature\", \"streamId\": \"5.Pump.Temperature\", \"dataFilterId\": null }, { \"selected\": false, \"name\": null, \"bodeId\": \"ns=5;s=Pump.FlowRate\", \"streamId\": \"5.Pump.FlowRate\", \"dataFilterId\": null } ]"
                                                         },
    "content/configuration/security.html":  {
                                                "href":  "content/configuration/security.html",
                                                "title":  "Security",
                                                "keywords":  "Security The OPC UA security standard is concerned with the authentication of client and server applications, the authentication of users, and confidentiality of their communication. Because the security model relies heavily on Transport Level Security (TLS) to establish a secure communication link with an OPC UA server, each client, including the adapter, must have a digital certificate deployed and configured. Certificates uniquely identify client applications and machines on servers, and allow for creation of a secure communication link when trusted on both sides. The adapter generates a self-signed certificate when the first secure connection attempt is made. The adapter\u0027s certificates and those of the server are stored in the certificate store, which is shared between all adapter instances. When determining OPC UA security practices with regards to REST APIs, you should consider the following practice. To keep the adapter secure, only administrators should have access to machines where the adapter is installed. REST APIs are bound to localhost, meaning that only requests coming from within the machine will be accepted. Adapter Certificate OPC UA connections may use certificates for identification and encryption. If needed, the OPC UA adapter will generate a self-signed certificate. The generated certificate will expire 10 years from the date of generation. When the adapter certificate approaches expiration, warnings will be logged daily starting 30 days prior to expiration. After the certificate is expired, errors will be logged daily. To generate a new self-signed certificate, move or delete the OpcUa\\Certificates\\own directory and restart the adapter. Configure OPC UA adapter security Complete the following steps to configure adapter security: In your data source configuration, set UseSecureConnection to true . For more information, see AVEVA Adapter for OPC UA data source configuration . The adapter verifies whether the server certificate is present in the adapter trusted certificates and hence trusts it. In case the certificates were not exchanged before the first attempted connection, the adapter persists the server certificate within the adapter rejected certificates folder. The following warning message about the rejected server certificate will be printed: ~~2019-09-08 11:45:48.093 +01:00~~ [Warning] Rejected Certificate: \"DC=MyServer.MyDomain.int, O=OSIsoft, CN=Simulation Manually move the server certificate from the Adapter rejected certificates location to the Adapter trusted certificates location using a file explorer or command-line interpreter. Linux example using command-line: sudo mv /usr/share/OSIsoft/Adapters/OpcUa/Certificates/rejected/certs/\u0027SimulationServer  usr share OSIsoft Adapters OpcUa Certificates rejected certs \u0027SimulationServer [F9823DCF607063DBCECCF6F8F39FD2584F46AEBB].der\u0027 /usr/share/OSIsoft/Adapters/OpcUa/Certificates/trusted/certs/  usr share OSIsoft Adapters OpcUa Certificates trusted certs  Note: Administrator or root privileges are required to perform this operation. Once the certificate is in the adapter trusted certificates folder, the adapter trusts the server and the connection attempt proceeds in making the connection call to the configured server. Add the certificate of the adapter to the server\u0027s trust store. The connection succeeds only when the adapter certificate is trusted on the server side. For more details on how to make a client certificate trusted, see your OPC UA server documentation. In general, servers work in a similar fashion to the clients, hence you can take a similar approach for making the client certificate trusted on the server side. When certificates are mutually trusted, the connection attempt succeeds and the adapter is connected to the most secure endpoint provided by the server. Certificate locations Adapter rejected certificates Windows: %programdata%\\OSIsoft\\Adapters\\OpcUa\\Certificates\\rejected\\certs Linux: /usr/share/OSIsoft/Adapters/OpcUa/Certificates/rejected/certs  usr share OSIsoft Adapters OpcUa Certificates rejected certs Adapter trusted certificates Windows: %programdata%\\OSIsoft\\Adapters\\OpcUa\\Certificates\\trusted\\certs Linux: /usr/share/OSIsoft/Adapters/OpcUa/Certificates/trusted/certs  usr share OSIsoft Adapters OpcUa Certificates trusted certs Certificate of the adapter Windows: %programdata%\\OSIsoft\\Adapters\\OpcUa\\Certificates\\own\\certs Linux: /usr/share/OSIsoft/Adapters/OpcUa/Certificates/own/certs  usr share OSIsoft Adapters OpcUa Certificates own certs Note: Access to the private key of the adapter requires administrator permissions. The location of the private key is the following: Windows: %programdata%\\OSIsoft\\Adapters\\OpcUa\\Certificates\\own\\private Linux: /usr/share/OSIsoft/Adapters/OpcUa/Certificates/own/private  usr share OSIsoft Adapters OpcUa Certificates own private"
                                            },
    "content/configuration/system-components.html":  {
                                                         "href":  "content/configuration/system-components.html",
                                                         "title":  "System components",
                                                         "keywords":  "System components AVEVA Adapters use JSON configuration files in a protected directory on Windows and Linux to store configuration that is read on startup. While the files are accessible to view, OSIsoft recommends that you use REST or the EdgeCmd utility for any changes you make to the files. As part of making adapters as secure as possible, any passwords or secrets that you configure are stored in encrypted form where cryptographic key material is stored separately in a secure location. If you edit the files directly, the adapter may not work as expected. Note: You can edit any single component or facet of the system individually using REST, but you can also configure the system as a whole with a single REST call. Configure system components Complete the following steps to configure system components. Use the PUT method in conjunction with the http://localhost:5590/api/v1/configuration/system/components http:  localhost:5590 api v1 configuration system components REST endpoint to initialize the configuration. Use a text editor to create an empty text file. Copy and paste an example configuration for system components into the file. For sample JSON, see Examples . Update the example JSON parameters for your environment. For a table of all available parameters, see System components parameters . Save the file. For example, as ConfigureComponents.json . Open a command line session. Change directory to the location of ConfigureComponents.json . Enter the following cURL command (which uses the PUT method) to initialize the system components configuration. curl -d \"@ConfigureComponents.json\" -H \"Content-Type: application/json\" application json\" -X PUT \"http://localhost:5590/api/v1/configuration/system/components\" \"http:  localhost:5590 api v1 configuration system components\" Notes: If you installed the adapter to listen on a non-default port, update 5590 to the port number in use. For a list of other REST operations you can perform, like updating or deleting a system components configuration, see REST URLs . System components schema The full schema definition for the system components configuration is in the System_Components_schema.json file located in one of the following folders: Windows: %ProgramFiles%\\OSIsoft\\Adapters\\AdapterName\\Schemas Linux: /opt/OSIsoft/Adapters/AdapterName/Schemas  opt OSIsoft Adapters AdapterName Schemas System components parameters You can configure the following parameters for system components: Parameters Required Type Description ComponentId Required string The ID of the component 1 . It can be any alphanumeric string. A properly configured ComponentID follows these rules:Cannot contain leading or trailing space Cannot use the following characters: \u003e \u003c /   : ? # [ ] @ ! $ \u0026 * \" ( ) \\\\ + , ; = ` ComponentType Required string The type of the component. There are two types of components: OmfEgress and the adapter. 1 1 Note: The OmfEgress component is required to run the adapter. Both its ComponentId and ComponentType are reserved and should not be modified. Examples Default system components configuration The default System_Components.json file for the System component contains the following information. [ { \"ComponentId\": \"OmfEgress\", \"ComponentType\": \"OmfEgress\" } ] System components configuration with two adapter instances [ { \"componentId\": \"OpcUa1\", \"componentType\": \"OpcUa\" }, { \"componentId\": \"OpcUa2\", \"componentType\": \"OpcUa\" }, { \"componentId\": \"OmfEgress\", \"componentType\": \"OmfEgress\" } ] REST URLs Relative URL HTTP verb Action api/v1/configuration/system/components api v1 configuration system components GET Retrieves the system components configuration api/v1/configuration/system/components api v1 configuration system components POST Adds a new component to the system configuration api/v1/configuration/system/components api v1 configuration system components PUT Updates the system components configuration api/v1/configuration/system/components/ api v1 configuration system components  ComponentId DELETE Deletes a specific component from the system components configuration api/v1/configuration/system/components/ api v1 configuration system components  ComponentId PUT Creates a new component with the specified ComponentId in the system configuration"
                                                     },
    "content/index.html":  {
                               "href":  "content/index.html",
                               "title":  "Overview",
                               "keywords":  "Overview AVEVA Adapter for OPC UA is a data-collection component that transfers time-series data from source devices to OMF endpoints in AVEVA Data Hub, AVEVA Servers, or Edge Data Store. OPC UA (OPC Unified Architecture) is an open standard, machine-to-machine communication protocol for industrial automation developed by the OPC Foundation. The adapter can connect to any device that uses the OPC UA communication protocol. Adapter installation You can install the adapter with a download kit that you can obtain from the OSIsoft Customer Portal. You can install the adapter on devices running either Windows or Linux operating systems. Adapter configuration Using REST API, you can configure all functions of the adapter. The configurations are stored in JSON files. For data ingress, you must define an adapter component in the system components configuration for each device to which the adapter will connect. You configure each adapter component with the connection information for the device and the data to collect. For data egress, you must specify destinations for the data, including security for the outgoing connection. Additional configurations are available to egress health and diagnostics data, add buffering configuration to protect against data loss, and record logging information for troubleshooting purposes. Once you have configured the adapter and it is sending data, you can use administration functions to manage the adapter or individual ingress components of the adapter. Health and diagnostics functions monitor the status of connected devices, adapter system functions, the number of active data streams, the rate of data ingress, the rate of errors, and the rate of data egress. EdgeCmd utility OSIsoft also provides the EdgeCmd utility, a proprietary command line tool to configure and administer an adapter on both Linux and Windows operating systems. EdgeCmd utility is installed separately from the adapter. \u003c!-- # AVEVA Adapter for OPC UA ======= - [AVEVA Adapter for OPC UA overview](xref:PIAdapterForOPCUAOverview) - [AVEVA Adapter for OPC UA principles of operation](xref:PIAdapterForOPCUAPrinciplesOfOperation) - [Installation](xref:Installation) - [Install the adapter](xref:InstallTheAdapter) - [Install AVEVA Adapter for OPC UA using Docker](xref:InstallPIAdapterForOPCUAUsingDocker) - [Uninstall the adapter](xref:UninstallTheAdapter) - [Configuration](xref:OPCUAConfiguration) - [Configuration tools](xref:ConfigurationTools) - [System components configuration](xref:SystemComponentsConfiguration) - [AVEVA Adapter for OPC UA data source configuration](xref:PIAdapterForOPCUADataSourceConfiguration) - [AVEVA Adapter for OPC UA data selection configuration](xref:PIAdapterForOPCUADataSelectionConfiguration) - [AVEVA Adapter for OPC UA security configuration](xref:PIAdapterForOPCUASecurityConfiguration) - [Egress endpoints configuration](xref:EgressEndpointsConfiguration) - [Health endpoint configuration](xref:HealthEndpointConfiguration) - [Diagnostics configuration](xref:DiagnosticsConfiguration) - [Buffering configuration](xref:BufferingConfiguration) - [Logging configuration](xref:LoggingConfiguration) - [System and adapter configuration](xref:SystemAndAdapterConfiguration) - [Administration](xref:Administration) - [Start and stop an adapter](xref:StartAndStopAnAdapter) - [Start and stop ingress component](xref:StartAndStopIngressComponent) - [Retrieve product version information](xref:RetrieveProductVersionInformation) - [Delete an adapter component](xref:DeleteAnAdapterComponent) - [Health and diagnostics](xref:HealthAndDiagnostics) - [Adapter health](xref:AdapterHealth) - [Device status](xref:DeviceStatus) - [Next health message expected](xref:NextHealthMessageExpected) - [Adapter diagnostics](xref:AdapterDiagnostics) - [System](xref:System) - [Stream count](xref:StreamCount) - [IO rate](xref:IORate) - [Error rate](xref:ErrorRate) - [Egress diagnostics](xref:EgressDiagnostics) --\u003e"
                           },
    "content/main/shared-content/_includes/inline/component-id.html":  {
                                                                           "href":  "content/main/shared-content/_includes/inline/component-id.html",
                                                                           "title":  "",
                                                                           "keywords":  "OpcUa1"
                                                                       },
    "content/main/shared-content/_includes/inline/component-type.html":  {
                                                                             "href":  "content/main/shared-content/_includes/inline/component-type.html",
                                                                             "title":  "",
                                                                             "keywords":  "OpcUa"
                                                                         },
    "content/main/shared-content/_includes/inline/docker-image.html":  {
                                                                           "href":  "content/main/shared-content/_includes/inline/docker-image.html",
                                                                           "title":  "",
                                                                           "keywords":  "opcuaadapter"
                                                                       },
    "content/main/shared-content/_includes/inline/framework-version.html":  {
                                                                                "href":  "content/main/shared-content/_includes/inline/framework-version.html",
                                                                                "title":  "",
                                                                                "keywords":  "1.7"
                                                                            },
    "content/main/shared-content/_includes/inline/installer-name.html":  {
                                                                             "href":  "content/main/shared-content/_includes/inline/installer-name.html",
                                                                             "title":  "",
                                                                             "keywords":  "AVEVA-Adapter-for-OpcUa-1.3.0.169"
                                                                         },
    "content/main/shared-content/_includes/inline/product-name.html":  {
                                                                           "href":  "content/main/shared-content/_includes/inline/product-name.html",
                                                                           "title":  "",
                                                                           "keywords":  "AVEVA Adapter for OPC UA"
                                                                       },
    "content/main/shared-content/_includes/inline/product-protocol.html":  {
                                                                               "href":  "content/main/shared-content/_includes/inline/product-protocol.html",
                                                                               "title":  "",
                                                                               "keywords":  ""
                                                                           },
    "content/main/shared-content/_includes/inline/product-version.html":  {
                                                                              "href":  "content/main/shared-content/_includes/inline/product-version.html",
                                                                              "title":  "",
                                                                              "keywords":  "1.4"
                                                                          },
    "content/main/shared-content/_includes/inline/startup-script.html":  {
                                                                             "href":  "content/main/shared-content/_includes/inline/startup-script.html",
                                                                             "title":  "",
                                                                             "keywords":  "opcuadockerstart.sh"
                                                                         },
    "content/main/shared-content/_includes/inline/symantic-version.html":  {
                                                                               "href":  "content/main/shared-content/_includes/inline/symantic-version.html",
                                                                               "title":  "",
                                                                               "keywords":  "1.3.0.169"
                                                                           },
    "content/main/shared-content/administration/administration.html":  {
                                                                           "href":  "content/main/shared-content/administration/administration.html",
                                                                           "title":  "Administration",
                                                                           "keywords":  "Administration With the AVEVA Adapter administration level functions, you can start and stop an adapter service and the individual adapter ingress components. You can also retrieve product version information and delete an adapter. The examples in the administration topics use curl , a commonly available tool on both Windows and Linux. You can use the same operations with any programming language or tool that supports making REST calls. You can also configure AVEVA Adapters with the EdgeCmd utility. For more information, see the EdgeCmd utility documentation . To validate successful configurations, you can accomplish data retrieval steps ( GET commands) using a browser, if available on your device. For more information on AVEVA Adapter configuration tools, see Configuration tools ."
                                                                       },
    "content/main/shared-content/administration/delete-an-adapter-component.html":  {
                                                                                        "href":  "content/main/shared-content/administration/delete-an-adapter-component.html",
                                                                                        "title":  "Delete an adapter component",
                                                                                        "keywords":  "Delete an adapter component When you remove an adapter component, the configuration and log files are saved into a sub-directory in case they are needed later. Any associated types, streams, and data remain on the respective endpoints. Complete the following steps to delete an adapter component: Start any of the Configuration tools capable of making HTTP requests. Run a DELETE command to the following endpoint: http://localhost:5590/api/v1/configuration/system/components/\u003cComponentId\u003e http:  localhost:5590 api v1 configuration system components \u003cComponentId\u003e Note: You must make an empty DELETE command against the Id of the component you want to delete. 5590 is the default port number. If you selected a different port number, replace it with that value. Example using curl : Delete an adapter component curl -X DELETE \"http://localhost:5590/api/v1/configuration/system/components/\u003cComponentId\u003e\" \"http:  localhost:5590 api v1 configuration system components \u003cComponentId\u003e\" File relocation All configuration and log files are renamed and moved when you remove an adapter component. The files are renamed according to the timestamp of removal. For example, FileName.json_removed_yyyy-MM-dd--hh-mm-ss . Configuration files are moved to the following location: Windows: %programdata%\\OSIsoft\\Adapters\\AdapterName\\Configuration\\Removed Linux: /usr/share/OSIsoft/Adapters/AdapterName/Configuration/Removed  usr share OSIsoft Adapters AdapterName Configuration Removed Log files are moved to the following location: Windows: %programdata%\\OSIsoft\\Adapters\\AdapterName\\Logs\\Removed Linux: /usr/share/OSIsoft/Adapters/AdapterName/Logs/Removed  usr share OSIsoft Adapters AdapterName Logs Removed In the following example, one adapter service is installed on a particular Windows node with the name \u003cAdapter\u003eService1 . An adapter component with the name \u003cAdapter\u003eDeviceX was added and configured to this adapter and later removed. Linux follows a similar behavior. This is the resulting relocation and renaming scheme after deletion: REST URLs Relative URL HTTP verb Action api/v1/configuration/system/components/\u003cComponentId\u003e api v1 configuration system components \u003cComponentId\u003e DELETE Deletes specified component Note: Replace \u003cComponentId\u003e with the Id of the component that you want to delete."
                                                                                    },
    "content/main/shared-content/administration/retrieve-product-version-information.html":  {
                                                                                                 "href":  "content/main/shared-content/administration/retrieve-product-version-information.html",
                                                                                                 "title":  "Retrieve product version information",
                                                                                                 "keywords":  "Retrieve product version information The product version information includes the adapter framework version, application version, the version of the underlying .NET Core framework, and the operating system that the adapter is running on. Complete the following steps to retrieve the product version information of a AVEVA Adapter: Use any of the Configuration tools capable of making HTTP requests. Run a GET command to the following endpoint: http://localhost:5590/api/v1/Diagnostics/ProductInformation http:  localhost:5590 api v1 Diagnostics ProductInformation Note: 5590 is the default port number. If you selected a different port number, replace it with that value. Example using curl : Get product information for adapter hosted on port 5590 curl -X GET \"http://localhost:5590/api/v1/Diagnostics/ProductInformation\" \"http:  localhost:5590 api v1 Diagnostics ProductInformation\" Example result: { \"Application Name\": \"AVEVA Adapter for \u003cAdapterName\u003e\", \"Adapter Framework Version\": \"1.3.0.351\", \"Application Version\":\"1.3.0.169\", \".Net Core Version\":\".NET Core 3.1.5\", \"Operating System\":\"Linux 4.15.0-106-generic #107-Ubuntu SMP Thu Jun 4 11:27:52 UTC 2020\" }"
                                                                                             },
    "content/main/shared-content/administration/server-redundancy-set.html":  {
                                                                                  "href":  "content/main/shared-content/administration/server-redundancy-set.html",
                                                                                  "title":  "Retrieve Redundant Server Set",
                                                                                  "keywords":  "Retrieve Redundant Server Set The AVEVA OPC UA Adapter provides a rest endpoint for querying the current redundant server set the adapter is using for server failover. Complete the following steps to retrieve the redundant server set of an AVEVA OPC UA Adapter: Use any of the Configuration tools capable of making HTTP requests. Run a GET command to the following endpoint: http://localhost:5590/api/v1/configuration/\u003cComponentId\u003e/RedundantServerSet http:  localhost:5590 api v1 configuration \u003cComponentId\u003e RedundantServerSet Note: 5590 is the default port number. If you selected a different port number, replace it with that value. Example using curl : Get redundant server set for adapter hosted on port 5590 curl -X GET \"http://localhost:5590/api/v1/configuration/\u003cComponentId\u003e/RedundantServerSet\" \"http:  localhost:5590 api v1 configuration \u003cComponentId\u003e RedundantServerSet\" Example result: { \"ServerAddresses\": [ \"opc.tcp://Server1\" \"opc.tcp:  Server1\" \"opc.tcp://Server2\" \"opc.tcp:  Server2\" ] }"
                                                                              },
    "content/main/shared-content/administration/start-and-stop-an-adapter.html":  {
                                                                                      "href":  "content/main/shared-content/administration/start-and-stop-an-adapter.html",
                                                                                      "title":  "Start and stop an adapter",
                                                                                      "keywords":  "Start and stop an adapter Complete the procedure appropriate for your operating system to start or stop an adapter service: Windows Open Windows services. Select AVEVA Adapter for \u003cAdapterName\u003e . Select Stop to stop your adapter or select Start to start your adapter. Linux Open command line. Confirm the status of your adapter, then run one of the following: To Start AVEVA Adapter for \u003cAdapterName\u003e: sudo systemctl start pi.adapter.\u003cadapterName\u003e To Stop AVEVA Adapter for \u003cAdapterName\u003e: sudo systemctl stop pi.adapter.\u003cadapterName\u003e Press Enter."
                                                                                  },
    "content/main/shared-content/administration/start-and-stop-ingress-component.html":  {
                                                                                             "href":  "content/main/shared-content/administration/start-and-stop-ingress-component.html",
                                                                                             "title":  "Start and stop ingress component",
                                                                                             "keywords":  "Start and stop ingress component To control data ingress, you can start and stop the ingress components of an adapter whenever necessary. Configured ingress components start by default. Start an ingress component Complete the following steps to start an individual ingress component: Use any of the Configuration tools capable of making HTTP requests. Run a POST command to the following endpoint, replacing \u003cComponentId\u003e with the ingress component that you want to start: http://localhost:5590/api/v1/administration/\u003cComponentId\u003e/Start http:  localhost:5590 api v1 administration \u003cComponentId\u003e Start Note: 5590 is the default port number. If you selected a different port number, replace it with that value. Example using curl : Start the adapter ingress component curl -d \"\" -X POST \"http://localhost:5590/api/v1/Administration/\u003cComponentId\u003e/Start\" \"http:  localhost:5590 api v1 Administration \u003cComponentId\u003e Start\" Stop an ingress component Complete the following steps to stop an individual ingress component: Start any configuration tool capable of making HTTP requests. Run a POST command to the following endpoint, replacing \u003cComponentId\u003e with the ingress component that you want to stop: http://localhost:5590/api/v1/administration/\u003cComponentId\u003e/Stop http:  localhost:5590 api v1 administration \u003cComponentId\u003e Stop Note: 5590 is the default port number. If you selected a different port number, replace it with that value. Example using curl : Stop the adapter ingress component curl -d \"\" -X POST \"http://localhost:5590/api/v1/Administration/\u003cComponentId\u003e/Stop\" \"http:  localhost:5590 api v1 Administration \u003cComponentId\u003e Stop\""
                                                                                         },
    "content/main/shared-content/configuration/buffering.html":  {
                                                                     "href":  "content/main/shared-content/configuration/buffering.html",
                                                                     "title":  "Buffering",
                                                                     "keywords":  "Buffering You can configure AVEVA Adapters to buffer data egressed from the adapter to endpoints. Buffering is configured through the buffering configuration parameters in the system configuration. Note: OSIsoft recommends that you do not modify the default buffering location unless it is necessary. Changes to the buffering configuration parameters only take effect during adapter service startup. Configure buffering Complete the following steps to configure buffering. Use the PUT method in conjunction with the http://localhost:5590/api/v1/configuration/system/buffering http:  localhost:5590 api v1 configuration system buffering REST endpoint to initialize the configuration. Use a text editor to create an empty text file. Copy and paste an example configuration for buffering into the file. For sample JSON, see Examples - Retrieve the buffering configuration . Update the example JSON parameters for your environment. For a table of all available parameters, see Buffering parameters . Save the file. For example, as ConfigureBuffering.json . Open a command line session. Change directory to the location of ConfigureBuffering.json . Enter the following curl command (which uses the PUT method) to initialize the buffering configuration. curl -d \"@ConfigureBuffering.json\" -H \"Content-Type: application/json\" application json\" -X PUT \"http://localhost:5590/api/v1/configuration/system/buffering\" \"http:  localhost:5590 api v1 configuration system buffering\" Notes: If you installed the adapter to listen on a non-default port, update 5590 to the port number in use. For a list of other REST operations you can perform, like updating or replacing a buffering configuration, see REST URLs . Buffering schema The full schema definition for the system buffering is in the System_Buffering_schema.json file located in one of the following folders: Windows: %ProgramFiles%\\OSIsoft\\Adapters\\\u003cAdapterName\u003e\\Schemas Linux: /opt/OSIsoft/Adapters/\u003cAdapterName\u003e/Schemas  opt OSIsoft Adapters \u003cAdapterName\u003e Schemas Buffering parameters The following parameters are available for configuring buffering: Parameter Required Type Description EnablePersistentBuffering Optional boolean Enables or disables on-disk buffering Allowed value: true or false Default value: true Note: If you disable persistent buffering, in-memory buffering is used. On-disk and in-memory buffering are limited by value in the MaxBufferSizeMB property. MaxBufferSizeMB Optional integer Defines the maximum size of the buffer that is persisted on disk 1 or used in memory 2 . The unit is specified in MB (1 Megabyte = 1048576 bytes). Consider the capacity and the type of storage medium to determine a suitable value for this parameter. Minimum value: 1 Maximum value: 2147483647 Default value: 1024 Note: The MaxBufferSizeMB property is applied to each configured endpoint. For example, if you set the MaxBufferSizeMB to 1024 and you configured the adapter to send data to two endpoints (for example, AVEVA Server and AVEVA Data Hub), the total maximum resources used for buffering will be 2048 . The health endpoint is an exception fixed at 20 MB. BufferLocation Required string Defines the location of the buffer files. Absolute paths are required. Consider the access-control list (ACL) when you set this parameter. BufferLocation is used to buffer files when EnablePersistentBuffering is true . Allowed value: Valid path to a folder location in the file system Default value: Windows: %ProgramData%\\OSIsoft\\Adapters\\\u003cAdapterInstance\u003e\\Buffers Linux: /usr/share/OSIsoft/Adapters/\u003cAdapterInstance\u003e/Buffers  usr share OSIsoft Adapters \u003cAdapterInstance\u003e Buffers 1 Buffering to disk - disk is only used if required; Data is only written to the disk buffer if queued in the memory buffer for more than 5 seconds. The MaxBufferSizeMB is applied per configured endpoint except the health endpoint. An adapter creates 20 MB buffer files that are stored in BufferLocation . When MaxBufferSizeMB is reached, the oldest buffer file is deleted and a new buffer file is created. The health endpoint is fixed at 20 MB. When the health endpoint buffer file becomes full, a new buffer file is created and the previous buffer file is deleted. Note: The following rules apply in case of an error when creating a new buffer file: Attempt to delete oldest buffer file and retry. If unable to buffer, errors are logged to indicate data loss. If a buffer file is corrupted, an attempt is made to recover individual records and any failure to recover records is logged. 2 Buffering only to memory : The MaxBufferSizeMB is applied per configured endpoint except the health endpoint. When MaxBufferSizeMB is reached, the oldest messages in the memory buffer are removed. Depending on the size of a new message, several old messages may be removed. The health endpoint is fixed at 20 MB. When the health endpoint buffer file becomes full, the oldest messages in the memory buffer are removed and new messages are added. Examples The following examples are buffering configurations made through the curl REST client. Retrieve the buffering configuration curl -X GET \"http://localhost:5590/api/v1/configuration/system/buffering\" \"http:  localhost:5590 api v1 configuration system buffering\" Sample output: { \"bufferLocation\": \"C:/ProgramData/OSIsoft/Adapters/\u003cAdapterName\u003e/Buffers\", \"C: ProgramData OSIsoft Adapters \u003cAdapterName\u003e Buffers\", \"maxBufferSizeMB\": 1024, \"enablePersistentBuffering\": true } 200 OK response indicates success. Update MaxBufferSizeMb parameter curl -d \"{ \\\"MaxBufferSizeMB\\\": 100 }\" -H \"Content-Type: application/json\" application json\" -X PATCH \"http://localhost:5590/api/v1/configuration/system/buffering\" \"http:  localhost:5590 api v1 configuration system buffering\" 204 No Content response indicates success. REST URLs Relative URL HTTP verb Action api/v1/configuration/system/buffering api v1 configuration system buffering GET Gets the buffering configuration api/v1/configuration/system/buffering api v1 configuration system buffering PUT Replaces the existing buffering configuration api/v1/configuration/system/buffering api v1 configuration system buffering PATCH Update parameter, partial configuration"
                                                                 },
    "content/main/shared-content/configuration/configuration-tools.html":  {
                                                                               "href":  "content/main/shared-content/configuration/configuration-tools.html",
                                                                               "title":  "Configuration tools",
                                                                               "keywords":  "Configuration tools You can configure AVEVA Adapters with the EdgeCmd utility, OSIsoft\u0027s proprietary tool for configuring adapters, or a commonly-used REST tool. EdgeCmd utility The EdgeCmd utility enables adapter configuration on both Linux and Windows operating systems. For more information on using the EdgeCmd utility, see the EdgeCmd utility documentation . REST tools The following tools are available to make REST calls: curl curl is a command line tool used to make HTTP calls and is supported on both Windows and Linux operating systems. You can script curl with Bash or PowerShell on Linux or Windows and you can use it to perform adapter administrative and programming tasks. curl commands are used in configuration and management examples throughout this document. For more information, see curl . Postman Postman is a REST tool for systems with GUI components. AVEVA Adapters are supported on platforms without GUIs. Postman is particularly useful for learning more about AVEVA Adapter REST APIs. For more information, see Postman ."
                                                                           },
    "content/main/shared-content/configuration/data-filters.html":  {
                                                                        "href":  "content/main/shared-content/configuration/data-filters.html",
                                                                        "title":  "Data filters",
                                                                        "keywords":  "Data filters AVEVA Adapters can be configured to perform data filtering to save network bandwidth. Every data item in the data selection configuration can be assigned the Id of a data filter. The adapter will then filter data for those data items based on the data filter configuration. Note: If data filters are enabled and data quality changes, both the old and current data quality values are passed on. Configure data filters Complete the following steps to configure data filters. Use the PUT method in conjunction with the http://localhost:5590/api/v1/configuration/\u003cComponentId\u003e/DataFilters http:  localhost:5590 api v1 configuration \u003cComponentId\u003e DataFilters REST endpoint to initialize the configuration. Use a text editor to create an empty text file. Copy and paste an example configuration for data filters into the file. For sample JSON, see Data filters example . Update the example JSON parameters for your environment. For a table of all available parameters, see Data filters parameters . Save the file. For example, as ConfigureDataFilters.json . Open a command line session. Change directory to the location of ConfigureDataFilters.json . Enter the following cURL command (which uses the PUT method) to initialize the data filters configuration. curl -d \"@ConfigureDataFilters.json\" -H \"Content-Type: application/json\" application json\" -X PUT \"http://localhost:5590/api/v1/configuration/\u003cComponentId\u003e/DataFilters\" \"http:  localhost:5590 api v1 configuration \u003cComponentId\u003e DataFilters\" Notes: If you installed the adapter to listen on a non-default port, update 5590 to the port number in use. For a list of other REST operations you can perform, like updating or deleting a data filters configuration, see REST URLs . On successful execution, the change that you have made to data filters takes effect immediately during runtime. Data filters schema The full schema definition for the data filters configuration is in the AdapterName_DataFilters_schema.json file located in one of the following folders: Windows: %ProgramFiles%\\OSIsoft\\Adapters\\\u003cAdapterName\u003e\\Schemas Linux: /opt/OSIsoft/Adapters/\u003cAdapterName\u003e/Schemas  opt OSIsoft Adapters \u003cAdapterName\u003e Schemas Data filters parameters The following parameters are available for configuring data filters: Parameter Required Type Description Id Required string Unique identifier for the data filter. Allowed value: any string identifier AbsoluteDeadband Optional double Specifies the absolute change in data value that should cause the current value to pass the filter test. Note: You must specify AbsoluteDeadband or PercentChange .Allowed value: double value representing absolute deadband numberDefault value: null PercentChange Optional double Specifies the percent change from previous value that should cause the current value to pass the filter test. Note: You must specify AbsoluteDeadband or PercentChange .Allowed value: double value representing percent change Default value: null ExpirationPeriod Optional timespan The length in time that can elapse after an event before automatically sending the next event, regardless of whether the next event passes the filter or not. The expected format is HH:MM:SS.### or SSS.* Allowed value: any timespan Default value: null * Note: For example, \"ExpirationPeriod\": 5:00 and \"ExpirationPeriod\": 300 both specify an expiration period of 5 minutes and 0 seconds. Data filters example [ { \"Id\": \"DuplicateData\", \"AbsoluteDeadband\": 0, \"PercentChange\": null, \"ExpirationPeriod\": \"01:00:00\" } ] REST URLs Relative URL HTTP verb Action api/v1/configuration/\u003cComponentId\u003e/DataFilters api v1 configuration \u003cComponentId\u003e DataFilters GET Gets all configured data filters. api/v1/configuration/\u003cComponentId\u003e/DataFilters api v1 configuration \u003cComponentId\u003e DataFilters DELETE Deletes all configured data filters. api/v1/configuration/\u003cComponentId\u003e/DataFilters api v1 configuration \u003cComponentId\u003e DataFilters POST Adds an array of data filters or a single data filter. Fails if any data filter already exists. api/v1/configuration/\u003cComponentId\u003e/DataFilters api v1 configuration \u003cComponentId\u003e DataFilters PUT Replaces all data. api/v1/configuration/\u003cComponentId\u003e/DataFilters api v1 configuration \u003cComponentId\u003e DataFilters PATCH Allows partial updating of configured data filter. api/v1/configuration/\u003cComponentId\u003e/DataFilters/\u003cId\u003e api v1 configuration \u003cComponentId\u003e DataFilters \u003cId\u003e GET Gets configured data filter by \u003cId\u003e. api/v1/configuration/\u003cComponentId\u003e/DataFilters/\u003cId\u003e api v1 configuration \u003cComponentId\u003e DataFilters \u003cId\u003e DELETE Deletes configured data filter by \u003cId\u003e. api/v1/configuration/\u003cComponentId\u003e/DataFilters/\u003cId\u003e api v1 configuration \u003cComponentId\u003e DataFilters \u003cId\u003e PUT Replaces data filter by \u003cId\u003e. Fails if data filter does not exist. Note: Replace \u003cComponentId\u003e with the Id of your adapter component."
                                                                    },
    "content/main/shared-content/configuration/diagnostics-and-metadata.html":  {
                                                                                    "href":  "content/main/shared-content/configuration/diagnostics-and-metadata.html",
                                                                                    "title":  "Diagnostics and metadata",
                                                                                    "keywords":  "Diagnostics and metadata You can configure AVEVA Adapters to produce and store diagnostics data at a designated health endpoint, and to send metadata for created streams. For more information about available diagnostics data, see Adapter diagnostics and Egress diagnostics . For more information about available metadata and what metadata are sent per metadata level, see Adapter Metadata . Configure general Start any of the Configuration tools capable of making HTTP requests. Run a PUT command to the following endpoint, setting EnableDiagnostics to either true or false , MetadataLevel to None , Low , Medium , or High and HealthPrefix to a string or null : http://localhost:5590/api/v1/configuration/system/general http:  localhost:5590 api v1 configuration system general Note: 5590 is the default port number. If you selected a different port number, replace it with that value. Example using curl : curl -d \"{ \\\"EnableDiagnostics\\\":true, \\\"MetadataLevel\\\":Medium, \\\"HealthPrefix\\\":\\\"Machine1\\\" }\" -X PUT \"http://localhost:5590/api/v1/configuration/system/general\" \"http:  localhost:5590 api v1 configuration system general\" General schema The full schema definition for the general configuration is in the System_General_schema.json file located in one of the following folders: Windows: %ProgramFiles%\\OSIsoft\\Adapters\\\u003cAdapterName\u003e\\Schemas Linux: /opt/OSIsoft/Adapters/\u003cAdapterName\u003e/Schemas  opt OSIsoft Adapters \u003cAdapterName\u003e Schemas General parameters The following parameters are available for configuring general: Parameter Required Type Description EnableDiagnostics Optional boolean Determines if diagnostics are enabled Allow value: true or false Default value: true MetadataLevel Optional reference Defines amount of metadata sent to OMF endpoints. Allowed value: None , Low , Medium , and High Default value: Medium HealthPrefix Optional reference Prefix to use for health and diagnostics stream and asset IDs. Default value: null Example Retrieve the general configuration Example using curl : curl -X GET \"http://localhost:{port}/api/v1/configuration/system/general\" \"http:  localhost:{port} api v1 configuration system general\" Sample output: { \"EnableDiagnostics\": true, \"MetadataLevel\": \"Medium\", \"HealthPrefix\": \"Machine1\" } REST URLs Relative URL HTTP verb Action api/v1/configuration/system/General api v1 configuration system General GET Gets the general configuration api/v1/configuration/system/General api v1 configuration system General PUT Replaces the existing general configuration api/v1/configuration/system/General api v1 configuration system General PATCH Allows partial updating of general configuration"
                                                                                },
    "content/main/shared-content/configuration/discovery.html":  {
                                                                     "href":  "content/main/shared-content/configuration/discovery.html",
                                                                     "title":  "Discovery",
                                                                     "keywords":  "Discovery You can perform a data discovery for existing data items on demand. Data discovery is initiated through REST calls and it is tied to a specific discovery Id, which you can either specify or allow the adapter to generate. Data discovery includes different routes. For example, you can choose to do the following: Retrieve the discovery results Query the discovery status Cancel or delete discoveries Merge discovery results with the data selection configuration Retrieve results from a current discovery and compare it with results from a previous or discovery Retrieve results from a current discovery and compare it with results from a current data selection configuration Configure discovery Start any of the Configuration tools capable of making HTTP requests. Run a POST command with the Id of the discovery and autoSelect set to either true or false to the following endpoint: http://localhost:5590/api/v1/configuration/\u003cComponentId\u003e/Discoveries http:  localhost:5590 api v1 configuration \u003cComponentId\u003e Discoveries . Notes: Including an Id is optional. If you do not include one, the adapter automatically generates one. 5590 is the default port number. If you selected a different port number, replace it with that value. Example using curl : curl -d \"{ \\\"Id\\\":\\\"TestDiscovery\\\", \\\"autoSelect\\\":true }\" -H \"Content-Type:application/json\" \"Content-Type:application json\" -X POST \"http://localhost:5590/api/v1/configuration/\u003cComponentId\u003e/Discoveries\" \"http:  localhost:5590 api v1 configuration \u003cComponentId\u003e Discoveries\" Discovery parameters Parameter Type Description id string The Id of the discovery Notes: ??? You cannot run multiple discoveries with the same Id.??? Including an id is optional. If you do not include one, the adapter automatically generates one. query string A filter that is specific to the data source. The query filter can limit the scope of the discovery.For more information, see the Data source configuration topic. startTime datetime Time when the discovery started endTime datetime Time when the discovery ended progress double Progress of the discovery itemsFound integer Number of data items that the discovery found on the data source newItems integer Number of new data items that the discovery found in comparison to the previous discovery resultUri integer URL at which you can access the results of the discovery autoSelect boolean When set to true , the result of the discovery gets pushed to the data selection configuration. status reference Status of the discovery, for example Active or Complete errors string Errors encountered during the discovery Discoveries status example The following example shows the status of all discoveries. The discovery id in this example was auto-generated. [ { \"id\": \"8ff855f1-a636-490a-bb31-207410a6e607\", \"query\": null, \"startTime\": \"2020-09-30T19:34:01.8180401+02:00\", \"endTime\": \"2020-09-30T19:34:01.8368776+02:00\", \"progress\": 30, \"itemsFound\": 4, \"newItems\": 0, \"resultUri\": \"http://127.0.0.1:5590/api/v1/Configuration/\u003cComponentId\u003e/Discoveries/8ff855f1-a636-490a-bb31-207410a6e607/result\", \"http:  127.0.0.1:5590 api v1 Configuration \u003cComponentId\u003e Discoveries 8ff855f1-a636-490a-bb31-207410a6e607 result\", \"autoSelect\": false, \"status\": \"Complete\", \"errors\": null } ] REST URLs Relative URL HTTP verb Action api/v1/configuration/ api v1 configuration  \u003ccomponentId\u003e /discoveries  discoveries GET Returns status of all discoveries api/v1/configuration/ api v1 configuration  \u003ccomponentId\u003e /discoveries  discoveries POST Initiates a new discovery and returns its Id api/v1/configuration/ api v1 configuration  \u003ccomponentId\u003e /discoveries  discoveries DELETE Cancels and deletes all saved discoveries api/v1/configuration/ api v1 configuration  \u003ccomponentId\u003e /discoveries/  discoveries  \u003cdiscoveryId\u003e GET Gets the status of an individual discovery Note: If a discovery with the specified Id does not exist, you will get an error message api/v1/configuration/ api v1 configuration  \u003ccomponentId\u003e /discoveries/  discoveries  \u003cdiscoveryId\u003e DELETE Cancels and deletes discovery and result api/v1/configuration/ api v1 configuration  \u003ccomponentId\u003e /discoveries/  discoveries  \u003cdiscoveryId\u003e /result  result GET Returns the result of a discovery api/v1/configuration/ api v1 configuration  \u003ccomponentId\u003e /discoveries/  discoveries  \u003cdiscoveryId\u003e /result?diff=  result?diff= previousId GET Returns the difference between the result and the previous result api/v1/configuration/ api v1 configuration  \u003ccomponentId\u003e /dataselection?diff=  dataselection?diff= \u003cdiscoveryId\u003e GET Returns the difference between the data selection configuration and the discovery results api/v1/configuration/ api v1 configuration  \u003ccomponentId\u003e /discoveries/  discoveries  \u003cdiscoveryId\u003e /result  result DELETE Cancels and deletes discovery result Note: The discovery Id is still valid, but a query will contain a status of canceled Only the Status property will contain a canceled status, but not the query api/v1/configuration/ api v1 configuration  \u003ccomponentId\u003e /discoveries/  discoveries  \u003cdiscoveryId\u003e /cancel  cancel POST Cancels the on-demand data source discovery api/v1/configuration/ api v1 configuration  \u003ccomponentId\u003e /dataselection/select?discoveryid=  dataselection select?discoveryid= \u003cdiscoveryId\u003e POST Adds the discovered items to data selection with selected set to true api/v1/configuration/ api v1 configuration  \u003ccomponentId\u003e /dataselection/unselect?discoveryid=  dataselection unselect?discoveryid= \u003cdiscoveryId\u003e POST Adds the discovered items to data selection with selected set to false Note: Replace \u003ccomponentId\u003e with the Id of your adapter component.Replace \u003cdiscoveryId\u003e with the Id of the discovery for which you want to perform the action."
                                                                 },
    "content/main/shared-content/configuration/egress-endpoints.html":  {
                                                                            "href":  "content/main/shared-content/configuration/egress-endpoints.html",
                                                                            "title":  "Egress endpoints",
                                                                            "keywords":  "Egress endpoints AVEVA Adapters collect time series data, which they can send to a permanent data store (endpoint). This operation is called data egress. The following endpoints are available for data egress: AVEVA Data Hub (ADH) AVEVA Servers through PI Web API For long term storage and analysis, you can configure any adapter to send time series data to one or several of these endpoints in any combination. An egress endpoint is comprised of the properties specified under Egress endpoint parameters . Data egress to a AVEVA Server creates a PI point in the AVEVA Adapter configuration. Data egress to AVEVA Data Hub creates a stream in the AVEVA Adapter configuration. The name of the PI point or AVEVA Data Hub stream is a combination of the StreamIdPrefix specified in the adapter data source configuration and the StreamId specified in the adapter data selection configuration. Configure egress endpoints Complete the following steps to configure egress endpoints. Use the PUT method in conjunction with the http://localhost:5590/api/v1/configuration/OmfEgress/dataendpoints http:  localhost:5590 api v1 configuration OmfEgress dataendpoints REST endpoint to initialize the configuration. Use a text editor to create an empty text file. Copy and paste an example configuration for egress endpoints into the file. For sample JSON, see Examples . Update the example JSON parameters for your environment. For a table of all available parameters, see Egress endpoint parameters . Save the file. For example, as ConfigureEgressEndpoints.json . Open a command line session. Change directory to the location of ConfigureEgressEndpoints.json . Enter the following cURL command (which uses the PUT method) to initialize the egress endpoints configuration. curl -d \"@ConfigureEgressEndpoints.json\" -H \"Content-Type: application/json\" application json\" -X PUT \"http://localhost:5590/api/v1/configuration/OmfEgress/dataendpoints\" \"http:  localhost:5590 api v1 configuration OmfEgress dataendpoints\" Notes: If you installed the adapter to listen on a non-default port, update 5590 to the port number in use. For a list of other REST operations you can perform, like updating or replacing an egress endpoints configuration, see REST URLs . Egress endpoint configuration schema The full schema definition for the egress endpoint configuration is in the OmfEgress_DataEndpoints_schema.json file located in one of the following folders: Windows: %ProgramFiles%\\OSIsoft\\Adapters\\\u003cAdapterName\u003e\\Schemas Linux: /opt/OSIsoft/Adapters/\u003cAdapterName\u003e/Schemas  opt OSIsoft Adapters \u003cAdapterName\u003e Schemas Egress endpoint parameters The following parameters are available for configuring egress endpoints: Parameter Required Type Description Id Optional string Unique identifierAllowed value: any string identifier Default value: new GUID Endpoint Required string Destination that accepts OMF v1.2 messages. Supported destinations include AVEVA Data Hub and AVEVA Server.Allowed value: well-formed http or https endpoint string Default: null Username Required for AVEVA Server endpoint string Basic authentication to the PI Web API OMF endpoint _AVEVA Server:_Allowed value: any string Default: null Note: If your username contains a backslash, you must add an escape character, for example, type OilCompany\\TestUser as OilCompany\\\\TestUser . Password Required for AVEVA Server endpoint string Basic authentication to the PI Web API OMF endpoint _AVEVA Server:_Allowed value: any string Default: null ClientId Required for AVEVA Data Hub endpoint string Authentication with the AVEVA Data Hub OMF endpoint Allowed value: any string, can be null if the endpoint URL schema is HTTP Default: null ClientSecret Required for AVEVA Data Hub endpoint string Authentication with the AVEVA Data Hub OMF endpoint Allowed value: any string, can be null if the endpoint URL schema is HTTP Default: null TokenEndpoint Optional for AVEVA Data Hub endpoint string Retrieves an AVEVA Data Hub token from an alternative endpoint Allowed value: well-formed http or https endpoint string Default value: null ValidateEndpointCertificate Optional boolean Disables verification of destination certificate. Note: Only use for testing with self-signed certificates. Allowed value: true or false Default value: true Special characters encoding The adapter encodes special characters used in the data selection StreamId parameter string before sending it to configured endpoints. The encoded characters look as follows: Special character Encoded character * %2a \u0027 %27 ` %60 \" %22 ? %3f ; %3b | %7c \\ %5c { %7b } %7d [ %5b ] %5d Examples The following examples are valid egress configurations: Egress data to AVEVA Data Hub [{ \"Id\": \"AVEVA Data Hub\", \"Endpoint\": \"https://\u003cAVEVA \"https:  \u003cAVEVA Data Hub OMF endpoint\u003e\", \"ClientId\": \"\u003cclientid\u003e\", \"ClientSecret\": \"\u003cclientsecret\u003e\" }] Egress data to PI Web API [{ \"Id\": \"PI Web API\", \"Endpoint\": \"https://\u003cpi \"https:  \u003cpi web AVEVA Server\u003e:\u003cport\u003e/piwebapi/omf/\", Server\u003e:\u003cport\u003e piwebapi omf \", \"UserName\": \"\u003cusername\u003e\", \"Password\": \"\u003cpassword\u003e\" }] REST URLs Relative URL HTTP verb Action api/v1/configuration/omfegress/DataEndpoints api v1 configuration omfegress DataEndpoints GET Gets all configured egress endpoints api/v1/configuration/omfegress/DataEndpoints api v1 configuration omfegress DataEndpoints DELETE Deletes all configured egress endpoints api/v1/configuration/omfegress/DataEndpoints api v1 configuration omfegress DataEndpoints POST Adds an array of egress endpoints or a single endpoint. Fails if any endpoint already exists api/v1/configuration/omfegress/DataEndpoints api v1 configuration omfegress DataEndpoints PUT Replaces all egress endpoints api/v1/configuration/omfegress/DataEndpoints api v1 configuration omfegress DataEndpoints PATCH Allows partial updating of configured endpoints. Note: The request must be an array containing one or more endpoints. Each endpoint in the array must include its Id . api/v1/configuration/omfegress/DataEndpoints/\u003cId\u003e api v1 configuration omfegress DataEndpoints \u003cId\u003e GET Gets configured endpoint by Id api/v1/configuration/omfegress/DataEndpoints/\u003cId\u003e api v1 configuration omfegress DataEndpoints \u003cId\u003e DELETE Deletes configured endpoint by Id api/v1/configuration/omfegress/DataEndpoints/\u003cId\u003e api v1 configuration omfegress DataEndpoints \u003cId\u003e PUT Updates or creates a new endpoint with the specified Id api/v1/configuration/omfegress/DataEndpoints/\u003cId\u003e api v1 configuration omfegress DataEndpoints \u003cId\u003e PATCH Allows partial updating of configured endpoint by Id Egress execution details After configuring an egress endpoint, egress is immediately run for that endpoint. Egress is handled individually per configured endpoint. When data is egressed for the first time, types and containers are egressed to the configured endpoint. After that only new or changed types or containers are egressed. Type creation must be successful in order to create containers. Container creation must be successful in order to egress data. If you delete an egress endpoint, data flow immediately stops for that endpoint. Buffered data in a deleted endpoint is permanently lost. Type, container, and data items are batched into one or more OMF messages when egressing. As per the requirements defined in OMF, a single message payload will not exceed 192KB in size. Compression is automatically applied to outbound egress messages. On the egress destination, failure to add a single item results in the message failing. Types, containers, and data are egressed as long as the destination continues to respond to HTTP requests."
                                                                        },
    "content/main/shared-content/configuration/egress-endpoints/configure-a-network-proxy.html":  {
                                                                                                      "href":  "content/main/shared-content/configuration/egress-endpoints/configure-a-network-proxy.html",
                                                                                                      "title":  "Configure a network proxy",
                                                                                                      "keywords":  "Configure a network proxy Some network architectures may need a network proxy between the AVEVA Adapter and the egress endpoint. The process for configuring the adapter to egress data through a network proxy varies depending on the proxy type. HTTPS forward proxy For the adapter to use an HTTPS forward proxy while egressing, configure the https_proxy environment variable. For information on how to configure system environment variables, refer to your platform specific documentation: Windows: setx Ubuntu: EnvironmentVariables Debian: EnvironmentVariables Docker: Environment variables in Compose The value of this environment variable must contain the URL of the proxy server, beginning with http . The format of the string is [user[:password]@]http://hostname[:port] [user[:password]@]http:  hostname[:port] . HTTPS proxy environment variable Parameter Required Description user Optional The user name for the HTTPS forward proxy. password Optional The password for the HTTPS forward proxy specified user name. If you specify user , password remains optional. port Optional If you do not specify port , the default 80 is used. Note: Usage of the https_proxy environment variable may affect other .NET or .NET Core applications. If you set this environment variable, it will affect the adapter egress endpoints and the adapter health endpoints. Examples: myUser@http://192.168.2.2 myUser@http:  192.168.2.2 myUser:myPassword@http://proxymachine.domain:3128 myUser:myPassword@http:  proxymachine.domain:3128 http://proxymachine.domain http:  proxymachine.domain In Windows, this may look something like: Example of an architecture with an https forward proxy: Reverse proxy For the adapter to use a reverse proxy while egressing, you must configure the reverse proxy as an egress endpoint. For information on how to configure an egress endpoint, see Egress endpoints configuration . Example: [{ \"Id\": \"PI Web API Through Proxy\", \"Endpoint\": \"https://\u003creverseProxy\u003e:\u003cport\u003e/piwebapi/omf/\", \"https:  \u003creverseProxy\u003e:\u003cport\u003e piwebapi omf \", \"UserName\": \"\u003cpiWebApiUser\u003e\", \"Password\": \"\u003cpiWebApiPassword\u003e\" }] Example of an architecture with a reverse proxy:"
                                                                                                  },
    "content/main/shared-content/configuration/egress-endpoints/prepare-egress-destinations.html":  {
                                                                                                        "href":  "content/main/shared-content/configuration/egress-endpoints/prepare-egress-destinations.html",
                                                                                                        "title":  "Prepare egress destinations",
                                                                                                        "keywords":  "Prepare egress destinations AVEVA Data Hub and AVEVA Server destinations may require additional configuration to receive OMF messages. AVEVA Data Hub To prepare AVEVA Data Hub to receive OMF messages from the adapter, create an OMF connection in AVEVA Data Hub. Creating an OMF connection results in an available OMF endpoint that can be used by the adapter egress mechanism. Complete the following steps to create an OMF connection: Create a Client . The Client Id and Client Secret will be used for the corresponding properties in the egress configuration. Create an OMF type Connection . The connection should link the created client to an existing [namespace]( https://docs.osisoft.com/bundle/AVEVA https:  docs.osisoft.com bundle AVEVA Data Hub/page/set-up/namespaces/namespaces-concept.html) Hub page set-up namespaces namespaces-concept.html) where the data will be stored. The OMF Endpoint URL for the connection will be used as the egress configuration Endpoint property. AVEVA Server To prepare a AVEVA Server to receive OMF messages from the adapter, a PI Web API OMF endpoint must be available. Complete the following steps: Install PI Web API and enable the Open MessageFormat (OMF) Services feature. During configuration, choose an AF database and PI Data Archive where metadata and data will be stored. The account used in an egress configuration needs permissions to create AF elements, element templates, and PI points. Configure PI Web API to use Basic authentication. For complete steps, as well as best practices and recommendations, see the following topic in the PI Web API User Guide: Authentication methods . Notes: The certificate used by PI Web API must be trusted by the device running the adapter, otherwise the egress configuration ValidateEndpointCertificate property needs to be set to false (this can be the case with a self-signed certificate but should only be used for testing purposes). To continue to send OMF egress messages to the PI Web API endpoint after upgrading PI Web API, restart the adapter service."
                                                                                                    },
    "content/main/shared-content/configuration/health-endpoints.html":  {
                                                                            "href":  "content/main/shared-content/configuration/health-endpoints.html",
                                                                            "title":  "Health endpoints",
                                                                            "keywords":  "Health endpoints You can configure AVEVA Adapters to produce and store health data at a designated health endpoint. You can use health data to ensure that your adapters are running properly and that data flows to the configured OMF endpoints. For more information about adapter health, see Adapter health . Configure health endpoint A health endpoint designates an OMF endpoint where adapter health information is sent. You can configure multiple health endpoints. Complete the following steps to configure health endpoints. Use the PUT method in conjunction with the http://localhost:5590/api/v1/configuration/system/healthendpoints http:  localhost:5590 api v1 configuration system healthendpoints REST endpoint to initialize the configuration. Use a text editor to create an empty text file. Copy and paste an example configuration for health endpoints into the file. For sample JSON, see Examples . Update the example JSON parameters for your environment. For a table of all available parameters, see Health endpoint parameters . Save the file. For example, as ConfigureHealthEndpoints.json . Open a command line session. Change directory to the location of ConfigureHealthEndpoints.json . Enter the following cURL command (which uses the PUT method) to initialize the health endpoint configuration. curl -d \"@ConfigureHealthEndpoints.json\" -H \"Content-Type: application/json\" application json\" -X PUT \"http://localhost:5590/api/v1/configuration/system/healthendpoints\" \"http:  localhost:5590 api v1 configuration system healthendpoints\" Notes: If you installed the adapter to listen on a non-default port, update 5590 to the port number in use. For a list of other REST operations you can perform, like updating or replacing a health endpoints configuration, see REST URLs . Health endpoints schema The full schema definition for the health endpoint configuration is in the System_HealthEndpoints_schema.json file located in one of the following folders: Windows: %ProgramFiles%\\OSIsoft\\Adapters\\\u003cAdapterName\u003e\\Schemas Linux: /opt/OSIsoft/Adapters/\u003cAdapterName\u003e/Schemas  opt OSIsoft Adapters \u003cAdapterName\u003e Schemas Health endpoint parameters The following parameters are available for configuring health endpoints: Parameter Required Type Description Id Optional string Uniquely identifies the endpoint. This can be any alphanumeric string. If left blank, a unique value is generated automatically. Allowed value: any string identifier Default value: new GUID Endpoint Required string The URL of the OMF endpoint to receive this health data Allowed value: well-formed http or https endpoint string Default: null Username Required for PI Web API endpoints string The username used to authenticate with a PI Web API OMF endpoint _AVEVA Server:_Allowed value: any string Default: null Password Required for PI Web API endpoints string The password used to authenticate with a PI Web API OMF endpoint _AVEVA Server:_Allowed value: any string Default: null ClientId Required for AVEVA Data Hub endpoints string The client ID used for authentication with an AVEVA Data Hub OMF endpoint Allowed value: any string Default: null ClientSecret Required for AVEVA Data Hub endpoints string The client secret used for authentication with an AVEVA Data Hub OMF endpoint Allowed value: any string Default: null TokenEndpoint Optional for AVEVA Data Hub endpoints string Retrieves an AVEVA Data Hub token from an alternative endpoint Allowed value: well-formed http or https endpoint string Default value: null ValidateEndpointCertificate Optional boolean Disables verification of destination security certificate. Use for testing only with self-signed certificates; OSIsoft recommends keeping this set to the default, true, in production environments. Allowed value: true or false Default value: true Examples AVEVA Data Hub endpoint { \"Id\": \"AVEVA Data Hub\", \"Endpoint\": \"https://\u003cAVEVA \"https:  \u003cAVEVA Data Hub OMF endpoint\u003e\", \"ClientId\": \"\u003cclientid\u003e\", \"ClientSecret\": \"\u003cclientsecret\u003e\" } PI Web API endpoint { \"Id\": \"PI Web API\", \"Endpoint\": \"https://\u003cpi \"https:  \u003cpi web AVEVA Server\u003e:\u003cport\u003e/piwebapi/omf/\", Server\u003e:\u003cport\u003e piwebapi omf \", \"UserName\": \"\u003cusername\u003e\", \"Password\": \"\u003cpassword\u003e\" } Note: When you use an adapter with a PI Web API health endpoint, the AF structure is required. If the elements are deleted, the adapter recreates the elements; if the account used to authenticate to the PI Web API has its permissions removed on the AF Server, the adapter retries sending health data to the PI Web API until the permissions are restored. REST URLs Relative URL HTTP verb Action api/v1/configuration/system/healthEndpoints api v1 configuration system healthEndpoints GET Gets all configured health endpoints api/v1/configuration/system/healthEndpoints api v1 configuration system healthEndpoints DELETE Deletes all configured health endpoints api/v1/configuration/system/healthEndpoints api v1 configuration system healthEndpoints POST Adds an array of health endpoints or a single endpoint. Fails if any endpoint already exists api/v1/configuration/system/healthEndpoints api v1 configuration system healthEndpoints PUT Replaces all health endpoints. Note: Requires an array of endpoints api/v1/configuration/system/healthEndpoints api v1 configuration system healthEndpoints PATCH Allows partial updating of configured health endpoints Note: The request must be an array containing one or more health endpoints. Each health endpoint in the array must include its Id . api/v1/configuration/system/healthEndpoints/\u003cId\u003e api v1 configuration system healthEndpoints \u003cId\u003e GET Gets configured health endpoint by \u003cId\u003e api/v1/configuration/system/healthEndpoints/\u003cId\u003e api v1 configuration system healthEndpoints \u003cId\u003e DELETE Deletes configured health endpoint by \u003cId\u003e api/v1/configuration/system/healthEndpoints/\u003cId\u003e api v1 configuration system healthEndpoints \u003cId\u003e PUT Updates or creates a new health endpoint with the specified \u003cId\u003e api/v1/configuration/system/healthEndpoints/\u003cId\u003e api v1 configuration system healthEndpoints \u003cId\u003e PATCH Allows partial updating of configured health endpoint by \u003cId\u003e Note: Replace \u003cId\u003e with the Id of the health endpoint."
                                                                        },
    "content/main/shared-content/configuration/history-recovery.html":  {
                                                                            "href":  "content/main/shared-content/configuration/history-recovery.html",
                                                                            "title":  "History recovery",
                                                                            "keywords":  "History recovery The adapter you are using supports the following data collection modes which you configure in the DataCollectionMode parameter of your adapter\u0027s data source configuration: CurrentOnly : The adapter component operates normally. History recovery is disabled. CurrentWithBackfill (Default): The adapter component operates normally, but disconnections and shutdown events are recorded in the form of recovery intervals. When the adapter is reconnected to a data source, it automatically backfills data for the recorded intervals. HistoryOnly : The adapter component does not get started. The adapter is able to start collecting historical data on demand. History recovery for adapters supports the following two operations related to the data collection mode: On demand history recovery : Recovers data from a specified start time or start and end time. If end time is not specified, the default is utcnow . On demand history recovery is available only when the adapter is in HistoryOnly data collection mode. Limited automatic history recovery : Backfills data gaps that originated from connection disruptions, data source issues, or AVEVA Adapter shutdown or both. This is limited to a maximum time-range of four days. Limited automatic history recovery is available only when the adapter is in CurrentWithBackfill data collection mode."
                                                                        },
    "content/main/shared-content/configuration/history-recovery/automatic-history-recovery.html":  {
                                                                                                       "href":  "content/main/shared-content/configuration/history-recovery/automatic-history-recovery.html",
                                                                                                       "title":  "Automatic history recovery",
                                                                                                       "keywords":  "Automatic history recovery In addition to on-demand history recovery, the AVEVA Adapter also supports automatic history recovery. For automatic history recovery, the adapter tracks changes to the DeviceStatus of each component. When the DeviceStatus changes to DeviceInError , Shutdown , or Attempting Failover , the adapter starts a new History recovery interval . The DeviceStatus changes to Good when the issue resolves or if the adapter restarts and then the adapter closes any current intervals for that component. The adapter tracks these intervals for each component and, when DeviceStatus has a value of Good , it performs history recovery for these intervals from oldest entry to newest. For more information, see also Device status . Note: If the data collection mode is set to CurrentWithBackfill , the adapter clears periods not recovered for the component and stops keeping track of them. Only if the data collection mode is set to HistoryOnly , an automatic history recovery operation in progress will be canceled, otherwise it will be finished. History recovery intervals Automatic history intervals cannot be longer than four days. If an interval is longer than four days, the adapter automatically changes the start time of the interval to be no earlier than four days before the end time prior to starting a recovery. If an outage lasts longer than four days, the adapter recovers up to four days before the current time when the device status finally improves. This avoids introducing additional data gaps."
                                                                                                   },
    "content/main/shared-content/configuration/history-recovery/on-demand-history-recovery-configuration.html":  {
                                                                                                                     "href":  "content/main/shared-content/configuration/history-recovery/on-demand-history-recovery-configuration.html",
                                                                                                                     "title":  "On-demand history recovery configuration",
                                                                                                                     "keywords":  "On-demand history recovery configuration The AVEVA Adapter supports performing history recovery on-demand by specifying start and end time. Configure history recovery Start any of the Configuration tools capable of making HTTP requests. Run a POST command with the Id of the history recovery, and the startTime and endTime to the following endpoint: http://localhost:5590/api/v1/configuration/\u003cComponentId\u003e/HistoryRecoveries http:  localhost:5590 api v1 configuration \u003cComponentId\u003e HistoryRecoveries . Example using curl : curl -d \"{ \\\"Id\\\":\\\"TestRecovery\\\", \\\"startTime\\\":\\\"2021-03-29T14:00:30Z\\\", \\\"endTime\\\":\\\"2021-03-29T15:00:15Z\\\" }\" -X POST \"http://localhost:5590/api/v1/configuration/\u003cComponentId\u003e/HistoryRecoveries\" \"http:  localhost:5590 api v1 configuration \u003cComponentId\u003e HistoryRecoveries\" Note: 5590 is the default port number. If you selected a different port number, replace it with that value. If you do not specify an Id, the endpoint generates a unique Id. History recovery parameters Parameter Type Description Id string The Id of the history recovery Note: You cannot run multiple history recoveries with the same Id. StartTime datetime Time when the first data items are collected. Note: Timestamps are interpreted into the Coordinated Universal Time (UTC) time standard. OSIsoft recommends the following format for entering a startTime in a curl command: YYYY-MM-DD T HH:MM:SS Z. EndTime datetime Time when the last data items are collected. Note: Timestamps are interpreted into the Coordinated Universal Time (UTC) time standard. OSIsoft recommends the following format for entering a endTime in a curl command: YYYY-MM-DD T HH:MM:SS Z. Checkpoint datetime The latest timestamp that the history recovery has completed with the range being between startTime and endTime . Items double The amount of data selection items in the history recovery operation. RecoveredEvents double Number of events that the history recovery found on the data source. Progress double Progress of the history recovery (number of data items found through the history recovery). Status enum Status of the history recovery.The following statuses are available: Active - The operation is currently in progress Complete - The operation has been completed Canceled - The operation has been canceled Failed - The operation failed Errors string Errors encountered during the history recovery. History recovery status example [ { \"Id\": \"HistoryRecovery1\", \"StartTime\": \"2021-01-09T05:55:00.0\", \"EndTime\": \"2021-01-26T13:20:00.0\", \"CheckPoint\": \"2021-01-13T14:55:00.0\", \"Items\": 7000, \"RecoveredEvents\": 800000, \"Progress\": 20, \"Status\": \"Active\", \"Errors\": null } ] Note: The result of the history recovery operation is added to the \u003ccomponentId\u003e_historyRecoveries.json file. REST URLs Relative URL HTTP verb Action api/v1/configuration/ api v1 configuration  \u003ccomponentId\u003e /historyRecoveries  historyRecoveries GET Returns all history recoveries statuses api/v1/configuration/ api v1 configuration  \u003ccomponentId\u003e /historyRecoveries  historyRecoveries POST Initiates a new history recovery, returns the id of the operation api/v1/configuration/ api v1 configuration  \u003ccomponentId\u003e /historyRecoveries  historyRecoveries DELETE Cancels all active history recovery operations and removes states api/v1/configuration/ api v1 configuration  \u003ccomponentId\u003e /historyRecoveries/  historyRecoveries  \u003coperationId\u003e GET Gets the status of an individual history recovery api/v1/configuration/ api v1 configuration  \u003ccomponentId\u003e /historyRecoveries/  historyRecoveries  \u003coperationId\u003e DELETE Cancels history recovery and removes the state api/v1/configuration/ api v1 configuration  \u003ccomponentId\u003e /historyRecoveries/  historyRecoveries  \u003coperationId\u003e /cancel  cancel POST Cancels history recovery api/v1/configuration/ api v1 configuration  \u003ccomponentId\u003e /historyRecoveries/  historyRecoveries  \u003coperationId\u003e /resume  resume POST Resumes canceled or failed history recovery operation ( 202 ) from the checkpoint Note: If the \u003coperationId\u003e is not found, a 404 HTTP error message will be returned Note: Replace \u003ccomponentId\u003e with the Id of your adapter component. Replace \u003coperationId\u003e with the Id of the history recovery operation for which you want to perform the action."
                                                                                                                 },
    "content/main/shared-content/configuration/logging.html":  {
                                                                   "href":  "content/main/shared-content/configuration/logging.html",
                                                                   "title":  "Logging",
                                                                   "keywords":  "Logging AVEVA Adapters write daily log messages for the adapter, the system, and OMF egress to flat text files in the following locations: ??? Windows: *%ProgramData%\\OSIsoft\\Adapters\\\u003cAdapterInstance\u003e\\Logs* ??? Linux: */usr/share/OSIsoft/Adapters/\u003cAdapterInstance\u003e/Logs* * usr share OSIsoft Adapters \u003cAdapterInstance\u003e Logs* Each message in the log displays the message severity level, timestamp, and the message itself. Configure logging Complete the following steps to configure logging. Use the PUT method in conjunction with the http://localhost:5590/api/v1/configuration/\u003cComponentId\u003e/Logging http:  localhost:5590 api v1 configuration \u003cComponentId\u003e Logging REST endpoint to initialize the configuration. Use a text editor to create an empty text file. Copy and paste an example configuration for logging into the file. For sample JSON, see Example . Update the example JSON parameters for your environment. For a table of all available parameters, see Logging parameters . Save the file. For example, as ConfigureLogging.json . Open a command line session. Change directory to the location of ConfigureLogging.json . Enter the following curl command (which uses the PUT method) to initialize the logging configuration. curl -d \"@ConfigureLogging.json\" -H \"Content-Type: application/json\" application json\" -X PUT \"http://localhost:5590/api/v1/configuration/\u003cComponentId\u003e/Logging\" \"http:  localhost:5590 api v1 configuration \u003cComponentId\u003e Logging\" Notes: If you installed the adapter to listen on a non-default port, update 5590 to the port number in use. For a list of other REST operations you can perform, like updating or retrieving a logging configuration, see REST URLs . Any parameter not specified in the updated configuration file reverts to the default schema value On successful execution, the log-level change takes effect immediately during runtime. The other configurations (log file size and file count) are updated after the adapter is restarted. Logging schema The full schema definition for the logging configuration is in the component specific logging file: AdapterName_Logging_schema.json , OmfEgress_Logging_schema.json , or System_Logging_schema.json file located in one of the following folders: Windows: %ProgramFiles%\\OSIsoft\\Adapters\\\u003cAdapterName\u003e\\Schemas Linux: /opt/OSIsoft/Adapters/\u003cAdapterName\u003e/Schemas  opt OSIsoft Adapters \u003cAdapterName\u003e Schemas Logging parameters The following parameters are available for configuring logging: Parameter Required Type Description LogLevel Optional reference The logLevel sets the minimum severity for messages to be included in the logs. Messages with a severity below the level set are not included. The log levels in their increasing order of severity are as follows: Trace , Debug , Information , Warning , Error , Critical , and None . Default log level: Information For detailed information about the log levels, see LogLevel . LogFileSizeLimitBytes Optional integer The maximum size (in bytes) of log files that the service will create for the component. The value must be a positive integer.Minimum value: 1000 Maximum value: 9223372036854775807 Default value: 34636833 LogFileCountLimit Optional integer The maximum number of log files that the service will create for the component. The value must be a positive integer.Minimum value: 1 Maximum value: 2147483647 Default value: 31 LogLevel Level Description Trace Logs that contain the most detailed messages. These messages may contain sensitive application data like actual received values, which is why these messages should not be enabled in production environment. Note: Trace is translated to Verbose in the log file. Debug Logs that can be used to troubleshoot data flow issues by recording metrics and detailed flow related information. Information Logs that track the general flow of the application. Any non-repetitive general information like the following can be useful for diagnosing potential application errors: - Version information related to the software at startup - External services used - Data source connection string - Number of measurements - Egress URL - Change of state ???Starting??? or ???Stopping??? - Configuration Warning Logs that highlight an abnormal or unexpected event in the application flow that does not otherwise cause the application execution to stop. Warning messages can indicate an unconfigured data source state, an insecure communication channel in use, or any other event that could require attention but that does not impact data flow. Error Logs that highlight when the current flow of execution is stopped due to a failure. These should indicate a failure in the current activity and not an application-wide failure. It can indicate an invalid configuration, unavailable external endpoint, internal flow error, and so on. Critical Logs that describe an unrecoverable application or system crash or a catastrophic failure that requires immediate attention. This can indicate application wide failures like beta timeout expired, unable to start self-hosted endpoint, unable to access vital resource (for example, Data Protection key file), and so on. Note: Critical is translated to Fatal in the log file. None Logging is disabled for the given component. Example Default logging configuration By default, logging captures Information, Warning, Error, and Critical messages in the message logs. The following logging configuration is the installation default for a component: { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 } REST URLs Relative URL HTTP verb Action api/v1/configuration/System/Logging api v1 configuration System Logging GET Retrieves the system logging configuration api/v1/configuration/System/Logging api v1 configuration System Logging PUT Updates the system logging configuration api/v1/configuration/\u003cComponentId\u003e/Logging api v1 configuration \u003cComponentId\u003e Logging GET Retrieves the logging configuration of the specified adapter component api/v1/configuration/\u003cComponentId\u003e/Logging api v1 configuration \u003cComponentId\u003e Logging PUT Updates the logging configuration of the specified adapter component Note: Replace \u003cComponentId\u003e with the Id of your adapter component."
                                                               },
    "content/main/shared-content/configuration/schedules.html":  {
                                                                     "href":  "content/main/shared-content/configuration/schedules.html",
                                                                     "title":  "Schedules",
                                                                     "keywords":  "Schedules You can configure the adapter to run scans based on a schedule. Each data item can be assigned to a schedule in the data selection configuration. The adapter samples data for those data items at the scheduled time. Note: You start an ingress component without a schedule configuration, a default schedule configuration is added to use as an example. Note: When the adapter framework scheduler misses or skips a scan for any reason, either one of the following messages is printed: Scan skipped for schedule id \u003cId\u003e or Scan missed for schedule \u003cid\u003e . Configure schedules Complete the following steps to change the schedules configuration: Using any text editor, create a file that contains the schedules configuration in the JSON format. For content structure, see the example schedule configuration . For all available parameters, see the schedules parameters . Save the file. For example, ConfigureSchedules.json . Use any of the Configuration tools capable of making HTTP requests to run a PUT command with the contents of the file to the following endpoint: http://localhost:5590/api/v1/configuration/\u003cComponentId\u003e/Schedules http:  localhost:5590 api v1 configuration \u003cComponentId\u003e Schedules . Note: Replace \u003cComponentId\u003e with the ComponentId of the adapter. 5590 is the default port number. If you selected a different port number, replace it with that value. Example using curl : Note: Run this command from the same directory where the file is located. curl -d \"@ConfigureSchedules.json\" -H \"Content-Type: application/json\" application json\" -X PUT \"http://localhost:5590/api/v1/configuration/\u003cComponentId\u003e/Schedules\" \"http:  localhost:5590 api v1 configuration \u003cComponentId\u003e Schedules\" On successful execution, the schedules change takes effect immediately during runtime. Schedules schema The full schema definition for the schedules configuration is in the AdapterName_Schedules_schema.json file located in one of the following folders: Windows: %ProgramFiles%\\OSIsoft\\Adapters\\\u003cAdapterName\u003e\\Schemas Linux: /opt/OSIsoft/Adapters/\u003cAdapterName\u003e/Schemas  opt OSIsoft Adapters \u003cAdapterName\u003e Schemas Schedules parameters The following parameters are available for configuring schedules: Parameter Required Type Description Id Required string Unique identifier for the scheduleAllowed value: any string identifier Period Required string The data sampling rate of the schedule. The expected format is HH:MM:SS.###. Invalid inputs: null , negative timespan, or zero A default value must be specified. Offset Optional string The offset from the midnight when the schedule starts. The expected format is HH:MM:SS.### Invalid input: negative timespan A default value must be specified. Note: You can also specify timespans as numbers in seconds. For example, \"Period\": 25 specifies 25 seconds, or \"Period\": 125 specifies 2 minutes and 5 seconds. Example schedule configuration The following is an example of a complete schedule configuration: [ { \"Id\": \"schedule1\", \"Period\": \"00:00:01.500\", \"Offset\": \"00:02:03\" } ] Default schedule configuration If no schedule is configured, the adapter uses the following default schedule configuration: [ { \"Id\": \"1\", \"Period\": \"0:00:05\", \"Offset\": \"0:00:00\" } ] REST URLs Relative URL HTTP verb Action api/v1/configuration/ api v1 configuration  ComponentId /Schedules  Schedules GET Gets all configured schedules api/v1/configuration/ api v1 configuration  ComponentId /Schedules  Schedules DELETE Deletes all configured schedules api/v1/configuration/ api v1 configuration  ComponentId /Schedules  Schedules POST Adds an array of schedules or a single schedule. Fails if any schedule already exists api/v1/configuration/ api v1 configuration  ComponentId /Schedules  Schedules PUT Replaces all schedules api/v1/configuration/ api v1 configuration  ComponentId /Schedules/  Schedules  id GET Gets configured schedule by id api/v1/configuration/ api v1 configuration  ComponentId /Schedules/  Schedules  id DELETE Deletes configured schedule by id api/v1/configuration/ api v1 configuration  ComponentId /Schedules/  Schedules  id PUT Replaces schedule by id . Fails if schedule does not exist api/v1/configuration/ api v1 configuration  ComponentId /Schedules/  Schedules  id PATCH Allows partial updating of configured schedule by id Note: Replace ComponentId with the Id of your adapter component."
                                                                 },
    "content/main/shared-content/configuration/system-and-adapter.html":  {
                                                                              "href":  "content/main/shared-content/configuration/system-and-adapter.html",
                                                                              "title":  "System and adapter",
                                                                              "keywords":  "System and adapter You can configure the system component and adapter component together using a single file. Change system and adapter configuration Complete the following steps to configure system and adapter. Use the PUT method in conjunction with the http://localhost:5590/api/v1/configuration http:  localhost:5590 api v1 configuration REST endpoint to initialize the configuration. Use a text editor to create an empty text file. Copy and paste an example configuration for system and adapter into the file. For sample JSON, see the corresponding adapter configuration examples topic. Save the file. For example, as ConfigureSystemAndAdapter.json . Open a command line session. Change directory to the location of ConfigureSystemAndAdapter.json . Enter the following curl command (which uses the PUT method) to initialize the system and adapter configuration. curl -d \"@ConfigureSystemAndAdapter.json\" -H \"Content-Type: application/json\" application json\" -X PUT \"http://localhost:5590/api/v1/configuration\" \"http:  localhost:5590 api v1 configuration\" Notes: If you installed the adapter to listen on a non-default port, update 5590 to the port number in use. In order for some of the adapter specific configurations to take effect, you have to restart the adapter. Discoveries and HistoryRecoveries facet details are not required to be supplied as part of the configuration and supplied values will be ignored. Their results will be restored from the previous states. If the operation fails due to errors in the configuration, the count of the error and suitable error messages are returned in the result. REST URLs Relative URL HTTP verb Action api/v1/configuration/ api v1 configuration  PUT Replaces the configuration for the entire adapter"
                                                                          },
    "content/main/shared-content/configuration/system-components.html":  {
                                                                             "href":  "content/main/shared-content/configuration/system-components.html",
                                                                             "title":  "System components",
                                                                             "keywords":  "System components AVEVA Adapters use JSON configuration files in a protected directory on Windows and Linux to store configuration that is read on startup. While the files are accessible to view, OSIsoft recommends that you use REST or the EdgeCmd utility for any changes you make to the files. As part of making adapters as secure as possible, any passwords or secrets that you configure are stored in encrypted form where cryptographic key material is stored separately in a secure location. If you edit the files directly, the adapter may not work as expected. Note: You can edit any single component or facet of the system individually using REST, but you can also configure the system as a whole with a single REST call. Configure system components Complete the following steps to configure system components. Use the PUT method in conjunction with the http://localhost:5590/api/v1/configuration/system/components http:  localhost:5590 api v1 configuration system components REST endpoint to initialize the configuration. Use a text editor to create an empty text file. Copy and paste an example configuration for system components into the file. For sample JSON, see Examples . Update the example JSON parameters for your environment. For a table of all available parameters, see System components parameters . Save the file. For example, as ConfigureComponents.json . Open a command line session. Change directory to the location of ConfigureComponents.json . Enter the following curl command (which uses the PUT method) to initialize the system components configuration. curl -d \"@ConfigureComponents.json\" -H \"Content-Type: application/json\" application json\" -X PUT \"http://localhost:5590/api/v1/configuration/system/components\" \"http:  localhost:5590 api v1 configuration system components\" Notes: If you installed the adapter to listen on a non-default port, update 5590 to the port number in use. For a list of other REST operations you can perform, like updating or deleting a system components configuration, see REST URLs . System components schema The full schema definition for the system components configuration is in the System_Components_schema.json file located in one of the following folders: Windows: %ProgramFiles%\\OSIsoft\\Adapters\\AdapterName\\Schemas Linux: /opt/OSIsoft/Adapters/AdapterName/Schemas  opt OSIsoft Adapters AdapterName Schemas System components parameters You can configure the following parameters for system components: Parameters Required Type Description ComponentId Required string The ID of the component 1 . It can be any alphanumeric string. A properly configured ComponentID follows these rules:Cannot contain leading or trailing space Cannot use the following characters: \u003e \u003c /   : ? # [ ] @ ! $ \u0026 * \" ( ) \\\\ + , ; = ` ComponentType Required string The type of the component. There are two types of components: OmfEgress and the adapter. 1 1 Note: The OmfEgress component is required to run the adapter. Both its ComponentId and ComponentType are reserved and should not be modified. Examples Default system components configuration The default System_Components.json file for the System component contains the following information. [ { \"ComponentId\": \"OmfEgress\", \"ComponentType\": \"OmfEgress\" } ] System components configuration with two adapter instances [ { \"ComponentId\": \"\u003cAdapterName\u003e1\", \"ComponentType\": \"\u003cAdapterName\u003e\" }, { \"ComponentId\": \"\u003cAdapterName\u003e2\", \"ComponentType\": \"\u003cAdapterName\u003e\" }, { \"ComponentId\": \"OmfEgress\", \"ComponentType\": \"OmfEgress\" } ] REST URLs Relative URL HTTP verb Action api/v1/configuration/system/components api v1 configuration system components GET Retrieves the system components configuration api/v1/configuration/system/components api v1 configuration system components POST Adds a new component to the system configuration api/v1/configuration/system/components api v1 configuration system components PUT Updates the system components configuration api/v1/configuration/system/components/\u003cComponentId\u003e api v1 configuration system components \u003cComponentId\u003e DELETE Deletes a specific component from the system components configuration api/v1/configuration/system/components/\u003cComponentId\u003e api v1 configuration system components \u003cComponentId\u003e PUT Creates a new component with the specified ComponentId in the system configuration"
                                                                         },
    "content/main/shared-content/configuration/text-parser/jsonpath-syntax-for-value-retrieval.html":  {
                                                                                                           "href":  "content/main/shared-content/configuration/text-parser/jsonpath-syntax-for-value-retrieval.html",
                                                                                                           "title":  "JSONPath syntax for value retrieval",
                                                                                                           "keywords":  "JSONPath syntax for value retrieval For information on which semantic is used for retrieving values from JSON files, see JSONPath Syntax . The following syntax is used to extract values from JSON documents. JSON - Simple JSONPath example [ { \"time\": \"2020-08-10T12:10:46.0928791Z\", \"value\": 1.234567890 }, { \"time\": \"2020-08-10T12:10:47.0928791Z\", \"value\": 12.34567890 }, { \"time\": \"2020-08-10T12:10:48.0928791Z\", \"value\": 123.4567890 }, { \"time\": \"2020-08-10T12:10:49.0928791Z\", \"value\": 1234.567890 }, { \"time\": \"2020-08-10T12:10:50.0928791Z\", \"value\": 12345.67890 }, { \"time\": \"2020-08-10T12:10:51.0928791Z\", \"value\": 123456.7890 }, { \"time\": \"2020-08-10T12:10:52.0928791Z\", \"value\": 12345678.90 }, { \"time\": \"2020-08-10T12:10:53.0928791Z\", \"value\": 123456789.0 } ] The following JSONPath configuration reads a series of values: { \"Id\": \"DoubleValue\", \"FieldDefinition\": \"value\", \"DataType\": \"Double\" }, { \"Id\": \"Timestamp\", \"FieldDefinition\": \"time\", \"DataType\": \"DateTime\", \"IsIndex\": true } JSON - Complex JSONPath examples The following example reads specific values from a JSON array: { \"StreamData\": { \"TPPrototype.uflsample.value_time\": [ { \"StreamId\": \"TPPrototype.uflsample.value_time\", \"DataType\": \"Double\", \"Timestamp\": \"2013-12-01T06:00:00Z\", \"Value\": 339.0 }, { \"StreamId\": \"TPPrototype.uflsample.value_time\", \"DataType\": \"Double\", \"Timestamp\": \"2013-12-01T07:00:00Z\", \"Value\": 344.0 }, { \"StreamId\": \"TPPrototype.uflsample.value_time\", \"DataType\": \"Double\", \"Timestamp\": \"2013-12-01T17:00:00Z\", \"Value\": 341.0 } ], \"TPPrototype.uflsample.value_timeString\": [ { \"StreamId\": \"TPPrototype.uflsample.value_timeString\", \"DataType\": \"String\", \"Timestamp\": \"2013-12-01T06:00:00Z\", \"Value\": \"339.0\" }, { \"StreamId\": \"TPPrototype.uflsample.value_timeString\", \"DataType\": \"String\", \"Timestamp\": \"2013-12-01T07:00:00Z\", \"Value\": \"344.0\" }, { \"StreamId\": \"TPPrototype.uflsample.value_timeString\", \"DataType\": \"String\", \"Timestamp\": \"2013-12-01T17:00:00Z\", \"Value\": \"341.0\" } ], \"TPPrototype.uflsample.pressure_time\": [ { \"StreamId\": \"TPPrototype.uflsample.pressure_time\", \"DataType\": \"Double\", \"Timestamp\": \"2013-12-01T06:00:00Z\", \"Value\": 339.0 }, { \"StreamId\": \"TPPrototype.uflsample.pressure_time\", \"DataType\": \"Double\", \"Timestamp\": \"2013-12-01T07:00:00Z\", \"Value\": 344.0 }, { \"StreamId\": \"TPPrototype.uflsample.pressure_time\", \"DataType\": \"Double\", \"Timestamp\": \"2013-12-01T17:00:00Z\", \"Value\": 341.0 } ] } } The following JSONPath configuration reads all the TPPrototype.uflsample.value_time values from the JSON above: { \"Id\": \"Value\", \"DataType\": \"Double\", \"FieldDefinition\": \"$[\u0027StreamData\u0027].[\u0027TPPrototype.uflsample.value_time\u0027][*].Value\" }, { \"Id\": \"Time\", \"DataType\": \"DateTime\", \"FieldDefinition\": \"$[\u0027StreamData\u0027].[\u0027TPPrototype.uflsample.value_time\u0027][*].Timestamp\", \"IsIndex\": true } The following example reads specific value from complex nested JSON: { \"success\": true, \"error\": null, \"result\": { \"type\": \"runtime_history\", \"chart\": { \"chart\": { \"type\": \"column\" }, \"title\": { \"text\": \"\" }, \"subtitle\": { \"text\": \"Daily History\" }, \"colors\": [ \"#fee292\", \"#fdc152\", \"#f69638\", \"#f17130\", \"#9f2d26\", \"#8acadc\", \"#184c8e\" ], \"series\": [ { \"name\": \"Stage 3 Aux Heat\", \"data\": [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ], \"stack\": \"heat\", \"state\": \"heat_aux_stage3\" }, { \"name\": \"Stage 2 Aux Heat\", \"data\": [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ], \"stack\": \"heat\", \"state\": \"heat_aux_stage2\" }, { \"name\": \"Aux Heat\", \"data\": [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ], \"stack\": \"heat\", \"state\": \"heat_aux\" }, { \"name\": \"Stage 2 Heat\", \"data\": [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ], \"stack\": \"heat\", \"state\": \"heat_stage2\" }, { \"name\": \"Heat\", \"data\": [ 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.3, 0.2, 0.0 ], \"stack\": \"heat\", \"state\": \"heat\" }, { \"name\": \"Stage 2 Cool\", \"data\": [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ], \"stack\": \"cool\", \"state\": \"cool_stage2\" }, { \"name\": \"Cool\", \"data\": [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ], \"stack\": \"cool\", \"state\": \"cool\" } ], \"xAxis\": { \"categories\": [ \"Friday\", \"Saturday\", \"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\" ], \"labels\": { \"rotation\": -45 } }, \"yAxis\": { \"allowDecimals\": false, \"min\": 0, \"max\": 24, \"tickInternval\": 4, \"title\": { \"text\": \"Runtime (Hours)\" } }, \"legend\": { \"layout\": \"vertical\", \"align\": \"center\", \"floating\": false, \"shadow\": false, \"itemStyle\": { \"fontSize\": \"1em\" } }, \"tooltip\": { \"shared\": true, \"borderColor\": \"#000000\" }, \"credits\": { \"enabled\": false }, \"plotOptions\": { \"column\": { \"stacking\": \"normal\" }, \"series\": { \"shadow\": false } } }, \"table\": { \"headings\": [ \"Fri\", \"Sat\", \"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\" ], \"series\": [ { \"name\": \"Aux Heat\", \"data\": [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ], \"stack\": \"heat\", \"state\": \"heat_aux\" }, { \"name\": \"Outdoor High Temp.\", \"data\": [ 72.0, 64.0, 73.0, 72.0, 67.0, 73.0, 77.0, 62.0, 51.0 ], \"stack\": null, \"state\": \"outdoor_high_temperature\" }, { \"name\": \"Outdoor Low Temp.\", \"data\": [ 55.0, 60.0, 62.0, 61.0, 51.0, 43.0, 46.0, 44.0, 35.0 ], \"stack\": null, \"state\": \"outdoor_low_temperature\" }, { \"name\": \"Avg Indoor Temp.\", \"data\": [ 76.0, 77.0, 78.0, 78.0, 77.0, 73.0, 74.0, 75.0, 72.0 ], \"stack\": null, \"state\": \"average_indoor_temperature\" }, { \"name\": \"Avg Indoor Humidity\", \"data\": [ 66.0, 68.0, 70.0, 70.0, 69.0, 67.0, 67.0, 66.0, 61.0 ], \"stack\": null, \"state\": \"average_indoor_humidity\" }, { \"name\": \"Fan Only Runtime\", \"data\": [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ], \"stack\": null, \"state\": \"fan_only\" }, { \"name\": \"Vent\", \"data\": [], \"stack\": null, \"state\": \"vent\" } ] }, \"show_monthly_runtime_history\": true } } The following JSONPath configuration reads Sunday Average Indoor Temperature. The timestamp comes from Adapter local time. { \"Id\": \"Temperature\", \"DataType\": \"Double\", \"FieldDefinition\": \"$.result.table.series[3].data[2]\" }, { \"Id\": \"Timestamp\", \"DataType\": \"DateTime\", \"Format\": \"Adapter\", \"IsIndex\": true } Error handling If you encounter text parser related errors that is errors for the ValueField or IndexField , check the StreamId associated with the error message. Possible errors include the following: The JSONPath expression of ValueField or IndexField is pointing to a non-existing value The JSONPath expression of ValueField or IndexField is missing a value altogether DataType does not match the value"
                                                                                                       },
    "content/main/shared-content/configuration/text-parser/text-parser.html":  {
                                                                                   "href":  "content/main/shared-content/configuration/text-parser/text-parser.html",
                                                                                   "title":  "Text parser",
                                                                                   "keywords":  "Text parser The adapter you are using includes the text parser component which ensures consistent parsing of text from different files. For more information on which file types are supported for your adapter, see the topics in this chapter. Designed to be a document parser, the text parser parses a semantically complete document in its entirety. The text parser produces OMF compatible output, which in turn is compatible with the AVEVA Data Hub backing SDS (Sequential Data Store) that stores data in streams consisting of multiple values and indexes. Data types supported by the text parser The following data types are supported by the text parser: DateTime DateTimeOffset TimeSpan sbyte byte short ushort int uint long ulong float double decimal bool char string Note: Not all data types supported by the text parser are also supported by OMF. Special characters support As part of the default StreamId logic, the text parser replaces special characters as follows: Special character Replacement character * empty string \u0027 empty string ` empty string \" empty string ? empty string ; - \\| - \\ - { ( } ) [ ( ] ) Culture support Some numeric values and datetimes support cultures when they are being parsed. The default culture is en-US (US English) (InvariantCulture). OSIsoft recommends that you leave the adapter at the default unless you expect culturally variant input. Note: Installed cultures vary by machine with both Linux and Windows. If the specified culture is not installed, the text parser fails to parse input that requires that culture. Time zone support A time zone or offset specified by a time is always used to convert to UTC time. Time zones are only used if there is no offset or time zone specifier in a text date and time string. For time zones that support time changes between daylight and standard times, a text file may temporarily contain invalid or ambiguous datetimes during the time change, which are possible only for a two-hour period each year. When these time changes occur, the text parser logs them, but the datetime is parsed and passed to the callback. Ambiguous times are reported as standard times, which is the Microsoft recommendation. Date and time processing The text parser can use time zones, cultures, and custom formats to read dates and times from ingress data. You can specify date and time formats when you configure data selection. Set the date and time using the IndexFormat property. If you leave the IndexFormat property unset, the data selection configuration defaults to the ISO 8601 date format. If you are using a culture other than default en-US , use the name of day or month specific to the culture. For example, use \"Juni\" instead of \"June\" for the de-DE culture. The following date and time syntaxes have been tested and are supported. \"MM/dd/yyyy \"MM dd yyyy H:mm:ss zzz\" \"06/15/2018 \"06 15 2018 15:15:30 -05:00\" \"MM/dd/yyyy \"MM dd yyyy H:mm:ss.fff zzz\" \"06/15/2018 \"06 15 2018 15:15:30.123 -05:00\" \"dd/MM/yyyy \"dd MM yyyy H:mm:ss.fff K\" \"15/06/2018 \"15 06 2018 15:15:30.123 Z\" \"MMMM/dd/yyyy \"MMMM dd yyyy H:mm:ss.fff K\" \"June/15/2018 \"June 15 2018 15:15:30.123 Z\" (InvariantCulture/English) (InvariantCulture English) \"MMMM/dd/yyyy \"MMMM dd yyyy H:mm:ss.fff K\" \"Juni/15/2018 \"Juni 15 2018 15:15:30.123 Z\" (German) \"MMM/dd/yyyy \"MMM dd yyyy H:mm:ss.fff K\" \"Jun/15/2018 \"Jun 15 2018 15:15:30.123 Z\" \"MMM-dd-yyyy H:mm:ss.fff K\" \"Jun-15-2018 15:15:30.123 Z\" \"MMM-dd-yyyy H:mm:ss.fff K\" \"Jun-15-2018 15:15:30.123 Z\" \"MMM-dd-yyyy H:mm:ss.fff K\" \"Jun-15-2018 15:15:30.123 Z\" \"yyyy-MM-dd H:mm:ss.fff K\" \"2018-06-15 15:15:30.123 Z\" \"yyyy-M-d H:mm:ss.fff K\" \"2018-6-5 15:15:30.123 Z\" \"yyyy-M-d H:mm:ss.fff zzz\" \"2018-6-5 15:15:30.123 +05:00\" \"ddd dd MMM yyyy h:mm tt zzz\" \"Sun 15 Jun 2008 8:30 AM -06:00\" \"dddd dd MMM yyyy h:mm tt zzz\" \"Sunday 15 Jun 2008 8:30 AM -06:00\" \"dddd dd MMM yyyy h:mm tt zzz\" \"Sunday 15 Jun 2008 8:30 AM -06:00\" \"dddd dd MMMM yyyy h:mm tt zzz\" \"Sunday 15 June 2008 8:30 AM -06:00\" Adapter date and time processing uses Microsoft datetime parsing . For more documentation on standard datetime formats, which fit most use cases, see Standard date and time format strings . For documentation on custom datetime formation, see Custom date and time format strings ."
                                                                               },
    "content/main/shared-content/configuration/text-parser/xpath-and-csv-syntax-for-value-retrieval.html":  {
                                                                                                                "href":  "content/main/shared-content/configuration/text-parser/xpath-and-csv-syntax-for-value-retrieval.html",
                                                                                                                "title":  "XPath and CSV syntax for value retrieval",
                                                                                                                "keywords":  "XPath and CSV syntax for value retrieval For information on which semantics are used for retrieving values from XML and CSV files, see the following documentation: XML - XML Path Language (XPath) CSV - Column Index (1 based) or Header value (if header defined) The following syntaxes are used to extract values from XML or CSV documents. XML - Simple XPath example \u003cvalues\u003e \u003cvalue\u003e \u003ctime\u003e2020-08-10T12:10:46.0928791Z\u003c/time\u003e \u003ctime\u003e2020-08-10T12:10:46.0928791Z\u003c time\u003e \u003cvalue\u003e1.234567890\u003c/value\u003e \u003cvalue\u003e1.234567890\u003c value\u003e \u003c/value\u003e \u003c value\u003e \u003cvalue\u003e \u003ctime\u003e2020-08-10T12:10:47.0928791Z\u003c/time\u003e \u003ctime\u003e2020-08-10T12:10:47.0928791Z\u003c time\u003e \u003cvalue\u003e12.34567890\u003c/value\u003e \u003cvalue\u003e12.34567890\u003c value\u003e \u003c/value\u003e \u003c value\u003e \u003cvalue\u003e \u003ctime\u003e2020-08-10T12:10:48.0928791Z\u003c/time\u003e \u003ctime\u003e2020-08-10T12:10:48.0928791Z\u003c time\u003e \u003cvalue\u003e123.4567890\u003c/value\u003e \u003cvalue\u003e123.4567890\u003c value\u003e \u003c/value\u003e \u003c value\u003e \u003cvalue\u003e \u003ctime\u003e2020-08-10T12:10:49.0928791Z\u003c/time\u003e \u003ctime\u003e2020-08-10T12:10:49.0928791Z\u003c time\u003e \u003cvalue\u003e1234.567890\u003c/value\u003e \u003cvalue\u003e1234.567890\u003c value\u003e \u003c/value\u003e \u003c value\u003e \u003cvalue\u003e \u003ctime\u003e2020-08-10T12:10:50.0928791Z\u003c/time\u003e \u003ctime\u003e2020-08-10T12:10:50.0928791Z\u003c time\u003e \u003cvalue\u003e12345.67890\u003c/value\u003e \u003cvalue\u003e12345.67890\u003c value\u003e \u003c/value\u003e \u003c value\u003e \u003cvalue\u003e \u003ctime\u003e2020-08-10T12:10:51.0928791Z\u003c/time\u003e \u003ctime\u003e2020-08-10T12:10:51.0928791Z\u003c time\u003e \u003cvalue\u003e123456.7890\u003c/value\u003e \u003cvalue\u003e123456.7890\u003c value\u003e \u003c/value\u003e \u003c value\u003e \u003cvalue\u003e \u003ctime\u003e2020-08-10T12:10:52.0928791Z\u003c/time\u003e \u003ctime\u003e2020-08-10T12:10:52.0928791Z\u003c time\u003e \u003cvalue\u003e12345678.90\u003c/value\u003e \u003cvalue\u003e12345678.90\u003c value\u003e \u003c/value\u003e \u003c value\u003e \u003cvalue\u003e \u003ctime\u003e2020-08-10T12:10:53.0928791Z\u003c/time\u003e \u003ctime\u003e2020-08-10T12:10:53.0928791Z\u003c time\u003e \u003cvalue\u003e123456789.0\u003c/value\u003e \u003cvalue\u003e123456789.0\u003c value\u003e \u003c/value\u003e \u003c value\u003e \u003c/values\u003e \u003c values\u003e The following XPath configuration reads a series of values: { \"Id\": \"DoubleValue\", \"FieldDefinition\": \"./values/value/value\", \". values value value\", \"DataType\": \"Double\" }, { \"Id\": \"Timestamp\", \"FieldDefinition\": \"./values/value/time\", \". values value time\", \"DataType\": \"DateTime\", \"IsIndex\": true } CSV - Simple CSV column index example 2020-08-10T12:10:46.0928791Z,1.234567890 2020-08-10T12:10:47.0928791Z,12.34567890 2020-08-10T12:10:48.0928791Z,123.4567890 2020-08-10T12:10:49.0928791Z,1234.567890 2020-08-10T12:10:50.0928791Z,12345.67890 2020-08-10T12:10:51.0928791Z,123456.7890 2020-08-10T12:10:52.0928791Z,12345678.90 2020-08-10T12:10:53.0928791Z,123456789.0 The following CSV column index configuration requires the text parser be configured with HasHeader=false . The column indexes are 1 based and configured as strings. { \"Id\": \"DoubleValue\", \"FieldDefinition\": \"2\", \"DataType\": \"Double\" }, { \"Id\": \"Timestamp\", \"FieldDefinition\": \"1\", \"DataType\": \"DateTime\", \"IsIndex\": true } CSV - Simple CSV column header example Date,Value 2020-08-10T12:10:46.0928791Z,1.234567890 2020-08-10T12:10:47.0928791Z,12.34567890 2020-08-10T12:10:48.0928791Z,123.4567890 2020-08-10T12:10:49.0928791Z,1234.567890 2020-08-10T12:10:50.0928791Z,12345.67890 2020-08-10T12:10:51.0928791Z,123456.7890 2020-08-10T12:10:52.0928791Z,12345678.90 2020-08-10T12:10:53.0928791Z,123456789.0 The following CSV column header configuration requires the text parser be configured with HasHeader=true . { \"Id\": \"DoubleValue\", \"FieldDefinition\": \"Value\", \"DataType\": \"Double\" }, { \"Id\": \"Timestamp\", \"FieldDefinition\": \"Date\", \"DataType\": \"DateTime\", \"IsIndex\": true }"
                                                                                                            },
    "content/main/shared-content/diagnostics/diagnostics.html":  {
                                                                     "href":  "content/main/shared-content/diagnostics/diagnostics.html",
                                                                     "title":  "Diagnostics",
                                                                     "keywords":  "Diagnostics The adapter and its components produce various kinds of diagnostics data that is sent to all health endpoints. The System_Diagnostics.json file contains a flag that determines whether diagnostics are enabled. You can change this at runtime through REST calls or the EdgeCmd utility. Diagnostics data are collected by default. To egress diagnostics related data, you have to configure an adapter health endpoint first. See Health endpoint configuration . Available diagnostics data Every minute, dynamic data is sent to configured health endpoints. The following diagnostics data are available: System Stream count IO rate Error rate"
                                                                 },
    "content/main/shared-content/diagnostics/egress.html":  {
                                                                "href":  "content/main/shared-content/diagnostics/egress.html",
                                                                "title":  "Egress",
                                                                "keywords":  "Egress The Egress component of the adapter produces the following diagnostics stream: IO rate The Diagnostics.Egress.IORate dynamic type includes the following values, which are logged in a stream with the Id {machineName}.{serviceName}.OmfEgress.{EndpointId}.IORate . IORate includes only sequential data successfully sent to an egress endpoint. Property Type Description timestamp string Timestamp of event IORate double One-minute rolling average of data rate (streams/second) (streams second)"
                                                            },
    "content/main/shared-content/diagnostics/error-rate.html":  {
                                                                    "href":  "content/main/shared-content/diagnostics/error-rate.html",
                                                                    "title":  "Error rate",
                                                                    "keywords":  "Error rate The Diagnostics.Adapter.ErrorRate dynamic type includes the following values, which are logged in a stream with the Id {componentid}.ErrorRate . Property Type Description timestamp string Timestamp of event ErrorRate double One-minute rolling average of error rate (streams/second) (streams second)"
                                                                },
    "content/main/shared-content/diagnostics/io-rate.html":  {
                                                                 "href":  "content/main/shared-content/diagnostics/io-rate.html",
                                                                 "title":  "IO rate",
                                                                 "keywords":  "IO rate The Diagnostics.Adapter.IORate dynamic type includes the following values, which are logged in a stream with the Id {componentid}.IORate . IORate includes only sequential data collected from a data source. Property Type Description timestamp string Timestamp of event IORate double One-minute rolling average of data rate (streams/second) (streams second)"
                                                             },
    "content/main/shared-content/diagnostics/stream-count.html":  {
                                                                      "href":  "content/main/shared-content/diagnostics/stream-count.html",
                                                                      "title":  "Stream count",
                                                                      "keywords":  "Stream count The Diagnostics.StreamCountEvent dynamic type includes the following values, which are logged in a stream with the Id {componentid}.StreamCount . The StreamCount and TypeCount include only types and streams created for sequential data received from a data source. Property Type Description timestamp string Timestamp of event StreamCount int Number of streams created by the adapter instance TypeCount int Number of types created by the adapter instance"
                                                                  },
    "content/main/shared-content/diagnostics/system.html":  {
                                                                "href":  "content/main/shared-content/diagnostics/system.html",
                                                                "title":  "System",
                                                                "keywords":  "System The Diagnostics.System dynamic type includes the following values which are logged in a stream with the Id System.Diagnostics . This diagnostic stream contains system level information related to the host platform on which the adapter is running. Property Type Description timestamp string Timestamp of event ProcessIdentifier int Process Id of the host process StartTime string Time at which the host process started WorkingSet long Amount of physical memory in bytes, allocated for the host process TotalProcessorTime double Total processor time for the host process expressed in seconds TotalUserProcessorTime double User processor time for the host process expressed in seconds TotalPrivilegedProcessorTime double Privileged processor time for the host process expressed in seconds ThreadCount int Number of threads in the host process HandleCount int Number of handles opened by the host process ManagedMemorySize double Number of bytes currently thought to be allocated in managed memory Unit of Measure = megabytes PrivateMemorySize double Amount of paged memory in bytes allocated for the host process Unit of Measure = megabytes PeakPagedMemorySize double Maximum amount of memory in the virtual memory paging file in bytes used by the host process. Unit of Measure = megabytes StorageTotalSize double Total size of the storage medium in use by the system Unit of Measure = megabytes StorageFreeSpace double Free space available Unit of Measure = megabytes Each adapter component produces its own diagnostics streams."
                                                            },
    "content/main/shared-content/health/device-status.html":  {
                                                                  "href":  "content/main/shared-content/health/device-status.html",
                                                                  "title":  "Device status",
                                                                  "keywords":  "Device status The device status indicates the health of this component and if it is currently communicating properly with the data source. This time-series data is stored within a PI point or AVEVA Data Hub stream, depending on the endpoint type. During healthy steady-state operation, a value of Good is expected. Property Type Description Time string Timestamp of the event DeviceStatus string The value of the DeviceStatus The possible statuses are: Status Meaning Good The component is connected to the data source and it is collecting data. ConnectedNoData The component is connected to the data source but it is not receiving data from it. Starting The component is currently in the process of starting up and is not yet connected to the data source. DeviceInError The component encountered an error either while connecting to the data source or attempting to collect data. Shutdown The component is either in the process of shutting down or has finished. Removed The adapter component has been removed and will no longer collect data. NotConfigured The adapter component has been created but is not yet configured. AttemptingFailover The adapter component is attempting server failover."
                                                              },
    "content/main/shared-content/health/health.html":  {
                                                           "href":  "content/main/shared-content/health/health.html",
                                                           "title":  "Health",
                                                           "keywords":  "Health AVEVA Adapters produce various kinds of health data that can be egressed to different health endpoints. To egress health related data, you have to configure an adapter health endpoint first. See Health endpoint configuration . Available health data Dynamic data is sent every minute to configured health endpoints. The following health data is available: Device status Next Health Message Expected"
                                                       },
    "content/main/shared-content/health/health-and-diagnostics.html":  {
                                                                           "href":  "content/main/shared-content/health/health-and-diagnostics.html",
                                                                           "title":  "Health and Diagnostics",
                                                                           "keywords":  "Health and Diagnostics AVEVA Adapters produce various types of health data. You can use health data to ensure that your adapters are running properly and that data flows to the configured OMF endpoints. For more information on available adapter health data, see health . AVEVA Adapters also produce diagnostic data. You can use diagnostic data to find more information about a particular adapter instance. Diagnostic data lives alongside the health data and you can egress it using a health endpoint and setting EnableDiagnostics to true . You can configure EnableDiagnostics in the system\u0027s General configuration . For more information on available adapter diagnostics data, see diagnostics . In AVEVA Data Hub (ADH), both health and diagnostics data are created as assets. The data are available in the Asset Explorer and you can use them in the AVEVA Data Hub Trend feature. For more information, see the AVEVA Data Hub documentation. Health endpoint differences Two OMF endpoints are currently supported for adapter health data: PI Web API AVEVA Data Hub (ADH) There are some differences in how these two systems treat the associated health and diagnostics data. PI Web API parses the information and sends it to configured AVEVA Servers for the OMF endpoint. The static data is used to create an AF structure on a PI AF server. The dynamic health data is time-series data that is stored in PI points on a PI Data Archive. You can see it in the AF structure as PI point data reference attributes. AVEVA Data Hub does not currently provide a way to store the static metadata. For AVEVA Data Hub-based adapter health endpoints, only the dynamic data is stored. Each value is its own stream with the timestamp property as the single index. AF structure With a health endpoint configured to a AVEVA Server, you can use PI System Explorer to view the health and diagnostics of an adapter. The element hierarchy is shown in the following image. The Elements root contains a link to an Adapters node. This is the root node for all adapter instances. Below Adapters , you will find one or more adapter nodes. Each node\u0027s title is defined by the node\u0027s corresponding computer name and service name in this format: {ComputerName}.{ServiceName} . For example, in the following image, MachineName is the computer name and OpcUa is the service name. To see the health and diagnostics values, select an adapter node and then select Attributes ."
                                                                       },
    "content/main/shared-content/health/next-health-message-expected.html":  {
                                                                                 "href":  "content/main/shared-content/health/next-health-message-expected.html",
                                                                                 "title":  "Next health message expected",
                                                                                 "keywords":  "Next health message expected This property is similar to a heartbeat. A new value for NextHealthMessageExpected is sent by an individual adapter data component on a periodic basis while it is functioning properly. This value is a timestamp that indicates when the next value should be received. When monitoring, if the next value is not received by the indicated time, this likely means that there is an issue. It could be an issue with the adapter, adapter component, network connection between the health endpoint and the adapter, and so on. Property Type Description Time string Timestamp of the event NextHealthMessageExpected string Timestamp when next value is expected"
                                                                             },
    "content/main/shared-content/installation/installation.html":  {
                                                                       "href":  "content/main/shared-content/installation/installation.html",
                                                                       "title":  "Installation",
                                                                       "keywords":  "Installation Adapters are installed on a local machine using an install kit downloaded from the OSIsoft Customer Portal. For instructions on downloading and installing adapters, see Install the adapter . Alternatively, you can build custom installers or containers for Linux. For more information, see the Docker instructions in the documentation of the respective adapter."
                                                                   },
    "content/main/shared-content/installation/install-the-adapter.html":  {
                                                                              "href":  "content/main/shared-content/installation/install-the-adapter.html",
                                                                              "title":  "Install the adapter",
                                                                              "keywords":  "Install the adapter You can install adapters on either a Windows or Linux operating system. Before installing the adapter, see the respective system requirements to ensure your machine is properly configured to provide optimum adapter operation. Windows Complete the following steps to install a AVEVA Adapter on a Windows computer: Download AVEVA-Adapter-for-OpcUa-1.3.0.169-x64_.msi from the OSIsoft Customer portal . Note: Customer login credentials are required to access the portal. Run the AVEVA-Adapter-for-OpcUa-1.3.0.169-x64_.msi file. Follow the setup wizard. You can change the installation folder or port number during setup. The default port number is 5590 . Optional: To verify the installation, run the following curl command with the port number that you specified during installation: curl http://localhost:5590/api/v1/configuration http:  localhost:5590 api v1 configuration If you receive an error, wait a few seconds and try the script again. If the installation was successful, a JSON copy of the default system configuration is returned. Linux Complete the following steps to install an adapter on a Linux computer: Download the appropriate Linux distribution file ( AVEVA-Adapter-for-OpcUa-1.3.0.169- platform _.deb ) from the OSIsoft Customer portal . Note: Customer login credentials are required to access the portal. Open a terminal. Run the sudo apt update command to update available packages information. Run the sudo apt install command against the Linux distribution file ( AVEVA-Adapter-for-OpcUa-1.3.0.169- platform _.deb ) selected in step 1 of this procedure. For example: sudo apt install ./AVEVA-Adapter-for-OpcUa-1.3.0.169-x64_.deb . AVEVA-Adapter-for-OpcUa-1.3.0.169-x64_.deb Optional: To verify the installation, run the following curl command with the port number that you specified during installation: curl http://localhost:5590/api/v1/configuration http:  localhost:5590 api v1 configuration If you receive an error, wait a few seconds and run the command again. If the installation was successful, a JSON copy of the default system configuration is returned."
                                                                          },
    "content/main/shared-content/installation/install-using-docker.html":  {
                                                                               "href":  "content/main/shared-content/installation/install-using-docker.html",
                                                                               "title":  "Installation using Docker",
                                                                               "keywords":  "Installation using Docker Docker is a set of tools that you can use on Linux to manage application deployments. This topic provides examples of how to create a Docker container with the adapter. Note: The use of Docker is only recommended if your environment requires it. Only users proficient with Docker should use it to install the adapter. Docker is not required to use the adapter. Create a startup script To create a startup script for the adapter, follow the instructions below. Use a text editor to create a script similar to one of the following examples: Note: The script varies slightly by processor. ARM32 #!/bin/sh #! bin sh if [ -z $portnum ] ; then exec /AVEVA-Adapter-for-OpcUa_1.3.0.169-arm_/OSIsoft.Data.System.Host  AVEVA-Adapter-for-OpcUa_1.3.0.169-arm_ OSIsoft.Data.System.Host else exec /AVEVA-Adapter-for-OpcUa_1.3.0.169-arm_/OSIsoft.Data.System.Host  AVEVA-Adapter-for-OpcUa_1.3.0.169-arm_ OSIsoft.Data.System.Host --port:$portnum fi ARM64 #!/bin/sh #! bin sh if [ -z $portnum ] ; then exec /AVEVA-Adapter-for-OpcUa_1.3.0.169-arm64_/OSIsoft.Data.System.Host  AVEVA-Adapter-for-OpcUa_1.3.0.169-arm64_ OSIsoft.Data.System.Host else exec /AVEVA-Adapter-for-OpcUa_1.3.0.169-arm64_/OSIsoft.Data.System.Host  AVEVA-Adapter-for-OpcUa_1.3.0.169-arm64_ OSIsoft.Data.System.Host --port:$portnum fi AMD64 #!/bin/sh #! bin sh if [ -z $portnum ] ; then exec /AVEVA-Adapter-for-OpcUa_1.3.0.169-x64_/OSIsoft.Data.System.Host  AVEVA-Adapter-for-OpcUa_1.3.0.169-x64_ OSIsoft.Data.System.Host else exec /AVEVA-Adapter-for-OpcUa_1.3.0.169-x64_/OSIsoft.Data.System.Host  AVEVA-Adapter-for-OpcUa_1.3.0.169-x64_ OSIsoft.Data.System.Host --port:$portnum fi Name the script opcuadockerstart.sh and save it to the directory where you plan to create the container. Create a Docker container To create a Docker container that runs the adapter, follow the instructions below. Create the following Dockerfile in the directory where you want to create and run the container. Note: Dockerfile is the required name of the file. Use the variation according to your operating system: ARM32 FROM ubuntu:20.04 WORKDIR /   RUN apt-get update \u0026\u0026 DEBIAN_FRONTEND=noninteractive apt-get install -y ca-certificates libicu66 libssl1.1 curl COPY opcuadockerstart.sh /   RUN chmod +x /opcuadockerstart.sh  opcuadockerstart.sh ADD ./AVEVA-Adapter-for-OpcUa_1.3.0.169-arm_.tar.gz . AVEVA-Adapter-for-OpcUa_1.3.0.169-arm_.tar.gz . ENTRYPOINT [\"/opcuadockerstart.sh\"] [\" opcuadockerstart.sh\"] ARM64 FROM ubuntu:20.04 WORKDIR /   RUN apt-get update \u0026\u0026 DEBIAN_FRONTEND=noninteractive apt-get install -y ca-certificates libicu66 libssl1.1 curl COPY opcuadockerstart.sh /   RUN chmod +x /opcuadockerstart.sh  opcuadockerstart.sh ADD ./AVEVA-Adapter-for-OpcUa_1.3.0.169-arm64_.tar.gz . AVEVA-Adapter-for-OpcUa_1.3.0.169-arm64_.tar.gz . ENTRYPOINT [\"/opcuadockerstart.sh\"] [\" opcuadockerstart.sh\"] AMD64 (x64) FROM ubuntu:20.04 WORKDIR /   RUN apt-get update \u0026\u0026 DEBIAN_FRONTEND=noninteractive apt-get install -y ca-certificates libicu66 libssl1.1 curl COPY opcuadockerstart.sh /   RUN chmod +x /opcuadockerstart.sh  opcuadockerstart.sh ADD ./AVEVA-Adapter-for-OpcUa_1.3.0.169-x64_.tar.gz . AVEVA-Adapter-for-OpcUa_1.3.0.169-x64_.tar.gz . ENTRYPOINT [\"/opcuadockerstart.sh\"] [\" opcuadockerstart.sh\"] Copy the AVEVA-Adapter-for-OpcUa-1.3.0.169- platform _.tar.gz file to the same directory as the Dockerfile . Copy the opcuadockerstart.sh script to the same directory as the Dockerfile . Run the following command line in the same directory ( sudo may be necessary): docker build -t opcuaadapter . Docker container startup The following procedures contain instructions on how to run the adapter inside a Docker container with different options enabled. Run the Docker container with REST access enabled To run the adapter inside a Docker container with access to its REST API from the local host, complete the following steps: Use the docker container image opcuaadapter created previously. Type the following in the command line ( sudo may be necessary): \u003c!-- PRERELEASE REMINDER: Customize for opcuaadapter. Example:bacnetadapter --\u003e docker run -d --network host opcuaadapter Port 5590 is accessible from the host and you can make REST calls to the adapter from applications on the local host computer. In this example, all data stored by the adapter is stored in the container itself. When you delete the container, the stored data is also deleted. Run the Docker container with persistent storage To run the adapter inside a Docker container while using the host for persistent storage, complete the following steps. This procedure also enables access to the adapter REST API from the local host. Use the docker container image opcuaadapter created previously. Type the following in the command line ( sudo may be necessary): docker run -d --network host -v /opcua:/usr/share/OSIsoft/  opcua: usr share OSIsoft  opcuaadapter Port 5590 is accessible from the host and you can make REST calls to the adapter from applications on the local host computer. In this example, all data that is typically written to the container is instead written to the host directory on the local machine. For example, /opcua  opcua . You can specify any directory. Change port number To use a different port other than 5590 , you can specify a portnum variable on the docker run command line. For example, to start the adapter using port 6000 instead of 5590 , use the following command: docker run -d -e portnum=6000 --network host opcuaadapter This command accesses the REST API with port 6000 instead of port 5590 . The following curl command returns the configuration for the container. curl http://localhost:6000/api/v1/configuration http:  localhost:6000 api v1 configuration Remove REST access To disable REST access from outside the container, remove the --network host option from the docker run command: docker run -d opcuaadapter ``` This may be of value where you want to host an application in the same container as the adapter but do not want to have external REST access enabled."
                                                                           },
    "content/main/shared-content/installation/system-requirements.html":  {
                                                                              "href":  "content/main/shared-content/installation/system-requirements.html",
                                                                              "title":  "System requirements",
                                                                              "keywords":  "System requirements AVEVA Adapter for OPC UA is supported on a variety of platforms and processors. Install kits are available for the following platforms: Operating System Platform Installation Kit Processor(s) Windows 10 Enterprise Windows 10 IoT Enterprise x64 AVEVA-Adapter-for-OpcUa-1.3.0.169-x64_.msi Intel/AMD Intel AMD 64-bit processors Debian 9, 10Ubuntu 18.04, 20.04 x64 AVEVA-Adapter-for-OpcUa-1.3.0.169-x64_.deb Intel/AMD Intel AMD 64-bit processors Debian 9, 10Ubuntu 20.04 ARM32 AVEVA-Adapter-for-OpcUa-1.3.0.169-arm_.deb ARM 32-bit processors Debian 10Ubuntu 20.04 ARM64 AVEVA-Adapter-for-OpcUa-1.3.0.169-arm64_.deb ARM 64-bit processors Alternatively, you can use tar.gz files with binaries to build your own custom installers or containers for Linux. For more information on installing the adapter with Docker containers, see Installation using Docker . PI Web API compatibility This version of AVEVA Adapter for OPC UA is compatible with PI Web API 2021 and later. AVEVA Adapter for OPC UA upgrade If you are upgrading AVEVA Adapter for OPC UA from version 1.1 to 1.3 and are sending data to PI Web API 2019, AVEVA Data Hub, or both, read OPC UA Adapter - Upgrade from v1.1 to v1.3 . This knowledge article contains important information about upgrade scenarios."
                                                                          },
    "content/main/shared-content/installation/uninstall-the-adapter.html":  {
                                                                                "href":  "content/main/shared-content/installation/uninstall-the-adapter.html",
                                                                                "title":  "Uninstall the adapter",
                                                                                "keywords":  "Uninstall the adapter Complete the procedure corresponding to your specific operating system to uninstall the adapter: Windows To delete the AVEVA Adapter program files from a Windows device, use the Windows Control Panel uninstall application process. Note: The configuration, data, and log files are not deleted by the uninstall process. Optional: To delete data, configuration, and log files, delete the directory: %ProgramData%\\OSIsoft\\Adapters\\\\[!include[product-name](../_includes/inline/component-type.md)] %ProgramData%\\OSIsoft\\Adapters\\\\[!include[product-name](.. _includes inline component-type.md)] This deletes all data processed by the adapter, in addition to the configuration and log files. Linux To delete AVEVA Adapter software from a Linux device, open a terminal window and run the following command: sudo apt remove pi.adapter.opcua Optional: To delete data, configuration, and log files, run the following command: sudo rm -r /usr/share/OSIsoft/Adapters/opcua  usr share OSIsoft Adapters opcua This deletes all data processed by the adapter, in addition to the configuration and log files."
                                                                            },
    "content/main/shared-content/installation/upgrade-the-adapter.html":  {
                                                                              "href":  "content/main/shared-content/installation/upgrade-the-adapter.html",
                                                                              "title":  "Upgrade the adapter",
                                                                              "keywords":  "Upgrade the adapter When a new version of the adapter is released, you can upgrade to the latest version by running the new installation package. Windows upgrade Complete the following steps to upgrade a AVEVA Adapter on a Windows computer: Download AVEVA-Adapter-for-OpcUa-1.3.0.169-x64_.msi from the OSIsoft Customer Portal . Note: Customer login credentials are required to access the portal. Run AVEVA-Adapter-for-OpcUa-1.3.0.169-x64_.msi . Complete the setup wizard. Optional: To verify the upgrade, run the following curl command with the port number that you specified when completing the wizard: curl -X GET \"http://localhost:5590/api/v1/Diagnostics/ProductInformation\" \"http:  localhost:5590 api v1 Diagnostics ProductInformation\" Upon successful upgrade, the JSON response lists the updated application version: { \"Application Version\": \"1.3.0.169\", //    upgraded version \".Net Core Version\": \".NET Core 3.1.15\", \"Operating System\": \"Microsoft Windows 10.0.19041\" } Linux upgrade Complete the following steps to upgrade a AVEVA Adapter on a Linux computer: Download the appropriate Linux distribution file from the OSIsoft Customer Portal . Note: Customer login credentials are required to access the portal. Open a terminal session. Move the Linux distribution file to the target host and run the sudo apt upgrade command. Platform Command Linux x64 sudo apt upgrade ./AVEVA-Adapter-for-OpcUa-1.3.0.169-x64_.deb . AVEVA-Adapter-for-OpcUa-1.3.0.169-x64_.deb Linux ARM32 Debian sudo apt upgrade ./AVEVA-Adapter-for-OpcUa-1.3.0.169-arm_.deb . AVEVA-Adapter-for-OpcUa-1.3.0.169-arm_.deb Linux ARM64 Debian sudo apt upgrade ./AVEVA-Adapter-for-OpcUa-1.3.0.169-arm64_.deb . AVEVA-Adapter-for-OpcUa-1.3.0.169-arm64_.deb Optional: To verify the upgrade, run the following curl command with the port number that you specified: curl -X GET \"http://localhost:5590/api/v1/Diagnostics/ProductInformation\" \"http:  localhost:5590 api v1 Diagnostics ProductInformation\" Upon successful upgrade, the JSON response lists the updated application version: { \"Application Version\": \"1.3.0.169\", //    upgraded version \".Net Core Version\": \".NET Core 3.1.15\", \"Operating System\": \"Microsoft Windows 10.0.19041\" }"
                                                                          },
    "content/main/shared-content/introduction/intro-to-pi-adapters.html":  {
                                                                               "href":  "content/main/shared-content/introduction/intro-to-pi-adapters.html",
                                                                               "title":  "AVEVA Adapter for OPC UA 1.4",
                                                                               "keywords":  "AVEVA Adapter for OPC UA 1.4 AVEVA Adapter for OPC UA is a data collection technology that collects time-series operations data from a data source over the protocol and then sends it to a supported storage location in the Open Message Format (OMF). \u003c!-- Add content about the protocol here --\u003e AVEVA Adapter for OPC UA data flow The following diagram depicts the collection and processing of data for an operational AVEVA Adapter for OPC UA, collecting and processing data. Refer to the list below the diagram for more information on each callout depicted. \u003c!-- Mark Bishop 3/3/22: 3 3 22: The SVG file referenced below can be opened and edited using https://app.diagrams.net/ https:  app.diagrams.net  --\u003e The user installs and configures AVEVA Adapter for OPC UA on a host system. You can configure the adapter using either a REST interface or EdgeCmd, a command line utility specifically designed for interfacing with edge systems. The adapter collects data from assets over the protocol, a process known as data ingress . The adapter converts ingress data to the Open Message Format (OMF), a format that supported storage locations understand. The adapter sends OMF data to a supported storage location in a process known as data egress . Supported egress endpoints include: AVEVA Server AVEVA Data Hub"
                                                                           },
    "content/main/shared-content/metadata/metadata.html":  {
                                                               "href":  "content/main/shared-content/metadata/metadata.html",
                                                               "title":  "Metadata",
                                                               "keywords":  "Metadata The Metadata Level in the System/General System General facet controls the amount of metadata written to an adapter stream and defines the amount of metadata sent to the OMF endpoints. It can be set to one of the following values: None - No metadata Low - Includes only framework related information Medium - Includes adapter specific information that is considered not sensitive High - All metadata (including potentially sensitive information and control addresses) If the metadataLevel is set to Low , Medium , or High in the General configuration , adapter streams created by the ingress components include the following metadata: Datasource: {ComponentId} AdapterType: {ComponentType} BrowseName: Medium LocalName: Medium SourceId: High ComponentId corresponds to the adapter components\u0027 data source configured in the Components configuration . ComponentType corresponds to the adapter type. Metadata for health and diagnostics streams If you configure a health endpoint and enable metadata, they are included in the health streams ( Device status and Next health message expected ) together with ComponentId and ComponentType . If you enable diagnostics in General configuration , metadata are included in the diagnostics streams ( Stream count , IO rate , Error rate ) together with ComponentId and ComponentType . The adapter may also send its own stream metadata not including health and diagnostics streams. For more information about what custom metadata is included in each stream, see the user guide for your adapter. Note: Metadata is only sent for streams created by the ingress components. Currently, the only endpoint that persists sent metadata is AVEVA Data Hub (ADH)."
                                                           },
    "content/main/shared-content/technical-support-and-feedback.html":  {
                                                                            "href":  "content/main/shared-content/technical-support-and-feedback.html",
                                                                            "title":  "Technical support and feedback",
                                                                            "keywords":  "Technical support and feedback OSIsoft provides several ways to report issues and provide feedback on AVEVA Adapters. Technical support For technical assistance with AVEVA Adapters, contact OSIsoft Technical Support through the OSIsoft Customer Portal . We can help you identify the problem, provide workarounds and address any concerns you may have. Remote access to your facilities may be necessary during the session. Note: You must have an account set up in the OSIsoft Customer Portal before you can open a case. If you do not have a portal account, see How to Get a Login to OSIsoft Customer Portal . Alternatively, call OSIsoft Technical Support at +1 510-297-5828. When you contact OSIsoft Technical Support, be prepared to provide this information: Product name, version, and build numbers Details about your computer platform (CPU type, operating system, and version number) Time that the difficulty started Log files at that time Details of any environment changes prior to the start of the issue Summary of the issue, including any relevant log files during the time the issue occurred \u003c!--To view a brief primer on AVEVA Adapters, see the [AVEVA Adapters playbook](https://customers.osisoft.com/s/knowledgearticle?knowledgeArticleUrl=Playbook-AVEVA-Adapters) playbook](https:  customers.osisoft.com s knowledgearticle?knowledgeArticleUrl=Playbook-AVEVA-Adapters) in the OSIsoft Customer Portal.--\u003e Product feedback To submit product feedback for AVEVA Adapters, visit the AVEVA Adapters feedback page . The product team at OSIsoft regularly monitors the page. Documentation feedback To submit documentation feedback for AVEVA Adapters, send an email to documentation@aveva.com . Be sure to include the following information with your feedback: Product name and version Documentation topic URL Details of the suggestion or error The technical documentation team will review and address your feedback in future documentation updates."
                                                                        },
    "content/main/shared-content/troubleshooting/troubleshooting.html":  {
                                                                             "href":  "content/main/shared-content/troubleshooting/troubleshooting.html",
                                                                             "title":  "Troubleshooting",
                                                                             "keywords":  "Troubleshooting AVEVA Adapters provide features for troubleshooting issues related to connectivity, data flow, and configuration. Resources include adapter logs and the Wireshark troubleshooting tool . If you are still unable to resolve issues or need additional guidance, contact OSIsoft Technical Support through the OSIsoft Customer Portal . Note: Make sure to also check the troubleshooting information specific to your adapter in this user guide. Logs Messages from the System and OmfEgress logs provide information on the status of the adapter. For example, the messages show if a connection from the adapter to an egress endpoint exists. Perform the following steps to view the System and OmfEgress logs: Navigate to the logs directory: Windows: %ProgramData%\\OSIsoft\\Adapters\\\u003cAdapterName\u003e\\Logs Linux: /usr/share/OSIsoft/Adapters/\u003cAdapterName\u003e/Logs  usr share OSIsoft Adapters \u003cAdapterName\u003e Logs Example: A successful connection to a PI Web API egress endpoint displays the following message in the OmfEgress log: 2020-11-02 11:08:51.870 -06:00 [Information] Data will be sent to the following OMF endpoint: Id: \u003comfegress id\u003e Endpoint: \u003cpi web api URL\u003e (note: the pi web api default port is 443) ValidateEndpointCertificate: \u003ctrue or false\u003e Optional : Change the log level of the adapter to receive more information and context. For more information, see Logging configuration . ASP .NET Core platform log The ASP .NET Core platform log provides information from the Kestrel web server that hosts the application. The log could contain information that the adapter is overloaded with incoming data. Perform the following steps to spread the load among multiple adapters: Decrease the scan frequency. Lower the amount of data selection items. Wireshark Wireshark is a protocol-specific troubleshooting tool that supports all current adapter protocols. Perform the following steps to use Wireshark to capture and analyze traffic from the data source to the adapter or from the adapter to the OMF destination. Download and install Wireshark . Familiarize yourself with the tool and read the Wireshark user guide . Health and diagnostics egress to PI Web API The adapter sends health and diagnostics data to PI Web API and, in some cases, conflicts may occur that are due to changes or perceived changes in PI Web API. For example, a 409 - Conflict error message displays if you upgrade your adapter version and the PI points do not match in the upgraded version. However, data is still sent as long as containers are present, so buffering only starts if no containers were created. To resolve the conflict, perform the following steps: Stop the adapter. Delete the Health folder inside of the Buffers folder. Stop PI Web API. Delete the relevant adapter created AF structure. Delete the associated health and diagnostics PI points on any or all PI Data Archives created by PI Web API. Start PI Web API. Start the adapter. Adapter connection to egress endpoint Certain egress health information in both PI Web API and AVEVA Data Hub show if an adapter connection to an egress endpoint exists. To verify an active connection, perform one of the following procedures: PI Web API connection Perform the following steps to determine if a connection to the PI Web API endpoint exists: Open PI Web API. Select the OmfEgress component of your adapter, for example GVAdapterUbuntu.\\\u003cAdapterName\\\u003e.OmfEgress . Make sure that the following PI points have been created for your egress endpoint: DeviceStatus NextHealthMessageExpected IORate AVEVA Data Hub connection Perform the following steps to determine if a connection to the AVEVA Data Hub endpoint exists: Open AVEVA Data Hub. Select Sequential Data Store \u003e Streams . Makes sure that the following streams have been created for your egress endpoint: DeviceStatus NextHealthMessageExpected IORate TCP connection Perform the following steps to see all established TCP sessions in Linux: Open a terminal. Type the following command: ss -o state established -t -p Press Enter."
                                                                         },
    "content/overview/principles-of-operation.html":  {
                                                          "href":  "content/overview/principles-of-operation.html",
                                                          "title":  "Principles of operation",
                                                          "keywords":  "Principles of operation This adapter\u0027s operations focus on data collection and stream creation. Adapter configuration For the OPC UA adapter to start data collection, configure the following: Data source: Provide the data source from which the adapter should collect data. Data selection: Select the OPC UA items to which the adapter should subscribe for data. Logging: Set up the logging attributes to manage the adapter logging behavior. For more information, see AVEVA Adapter for OPC UA data source configuration and AVEVA Adapter for OPC UA data selection configuration . Connection The OPC UA adapter uses the binary opc.tcp protocol to communicate with the OPC UA servers. As part of the OPC UA server and client establishing a secure connection, each one sends its X.509-type certificate to the other for verification. Upon verification of the certificates, the server and client establish a secure connection. For more information on secure connections, see AVEVA Adapter for OPC UA security configuration . Data collection The OPC UA adapter collects time-series data from selected OPC UA dynamic variables through OPC UA subscriptions (unsolicited reads). The adapter supports the Data Access (DA) and Historical Data Access (HDA) parts of OPC UA specification. For more information, see Data Access and Historical Data Access . Data types The following table lists OPC UA variable types that the adapter collects data from and types of streams that will be created. OPC UA data type Stream data type Boolean Boolean SByte Int16 Int16 Int16 UInt16 UInt16 Int32 Int32 UInt32 UInt32 Int64 Int64 UInt64 UInt64 Double Float64 Decimal Float32 Float Float32 DateTime DateTime UtcTime DateTime String String Number variable, depending on the actual value Integer Integer UInteger UInteger Enumeration Int16 AVEVA Adapter for OPC UA attempts to verify the data type for each data selection item before adding the item to the subscription on the OPC UA server. Verified data selection items with supported types and data selection items for which the type cannot be verified are added to the subscription. Data selection items with unsupported data type are not added to the subscription and a message including the NodeId and TypeId is logged. Enumeration types AVEVA Adapter for OPC UA supports the following enumeration types: MultiStateDiscreteType MultiStateValueDiscreteType TwoStateDiscreteType Any object that has a data type referenced as enumeration type The adapter reads the enumeration mapping for data selection items that point to any of the enumeration types and sends these items as enums to the OMF endpoints. Stream creation The OPC UA adapter creates a stream with three properties for each selected OPC UA item. The properties are described in the following table: Property name Data type Description Timestamp DateTime Timestamp of the given OPC UA item value update. Value Based on type of incoming OPC UA value Value of the given OPC UA item update, which includes multiple properties in addition to the data value. Note: For OPC UA items that support EURange, the additional Minimum /   Maximum properties in OCS and the Zero /   Span properties in AVEVA Web API are populated. For OPC UA items that support EngineeringUnits, such as AnalogItem, the additional UOM property in OCS and the Eng Units property in AVEVA Web API are populated. 1 Quality Unsigned integer Data quality of the given OPC UA item update. 1 Note: Null values with Good quality are discarded. Null values with Bad or Questionable quality send the default value 0 or null to the destination. The OPC UA adapter sends metadata with each stream it creates. Metadata common for every adapter type are: ComponentId : Specifies the data source. For example, OpcUa1 ComponentType : Specifies the type of adapter. For example, OpcUa Metadata specific to the OPC UA adapter are: BrowseName : The browse name as provided by the OPC UA server SourceId : The NodeId provided by the OPC UA server Note: A configured metadata level allows you to set the amount of metadata for the adapter. Specify the metadata level in the General configuration . For the OPC UA adapter, the following metadata is sent for the individual level: None : No metadata Low : AdapterType (ComponentType) and DataSource (ComponentId) Medium : AdapterType (ComponentType), DataSource (ComponentId), BrowseName, and DisplayName High : AdapterType (ComponentType), DataSource (ComponentId), BrowseName, DisplayName, and SourceId Each stream created by the adapter for a given OPC UA item has a unique identifier (Stream ID). If you specify a custom stream ID for the OPC UA item in data selection configuration, the OPC UA adapter uses that stream ID to create the stream. Otherwise, the adapter uses the OPC UA item node ID to construct the stream ID, as shown below. \u003cAdapterComponentID\u003e.\u003cNamespaceIndex\u003e.\u003cIdentifier\u003e NamespaceIndex refers to the number specified in the ns keyword in the NodeId parameter of the data selection configuration item. For more information, see AVEVAAdapter for OPC UA data source configuration . Note: The naming convention is affected by StreamPrefix and DefaultStreamIdPattern settings in the data source configuration. Server Failover The OPC UA adapter supports server failover, also known as non-transparent server redundancy. To enable this feature, the ServerFailoverEnabled property in the adapter component\u0027s DataSource must be set to true . For more information on setting this property, see PI Adapter for OPC UA data source configuration . Upon successful connection to the primary OPC UA Server that is defined in the Data Source configuration, the adapter will read 3 node ID\u0027s that hold server redundancy related information: Node ID How it\u0027s used i=3709 : Server redundancy mode support This value will be used to determine the redundancy mode the adapter will follow. Currently, the supported modes are None , Cold , Warm , and Hot . The adapter will only read this property from the primary OPC UA Server that is defined in the Data Source configuration. i=11314 : Server URI array This value will be used to determine all of the servers in the redundancy set. This should include the primary server as well as any additional backup servers. The adapter will only read this property from the primary OPC UA Server that is defined in the Data Source configuration. i=2267 : Service level This value will be used to track each server\u0027s health and determine if a failover should occur. The adapter will subscribe to this value on every server in the redundancy set. Note: The adapter does not currently support a runtime change to the server redundancy mode or server URI array. A user must restart the adapter if they wish to change either the server redundancy mode or the server URI array. Supported Redundancy Modes The following sections outline how the adapter behaves in each Server Redundancy Mode. For more information on server redundancy, see the OPC UA Online Reference part 4 - 6.6.2 None If the Server Redundancy Mode Support value on the primary OPC UA server is None , the adapter will operate as if server failover is not enabled. The adapter will not attempt to connect or failover to any backup servers. Cold If the servers in the redundancy set are operating in Cold mode, the adapter will take the following steps upon startup: Make a connection to each server defined in the primary OPC UA server\u0027s Server URI Array. Read the Service Level of each server to determine which server is the healthiest. Disconnect from all servers except for the healthiest. The adapter will only maintain a connection with a single OPC UA server after its initial startup. The secondary servers will not be connected to unless a server failover occurs. In Cold server failover, a failover only occurs if the adapter loses connection to the primary server or if the primary server\u0027s Service Level drops to 1 or 0. When this occurs, the adapter will connect to all secondary servers, read the service level of each, then disconnect from all servers except for the one with the highest service level. The adapter will maintain a connection with this new server until another failover event occurs. Warm If the servers in the redundancy set are operating in Warm mode, the adapter will take the following steps upon startup: Make a connection to each server defined in the primary OPC UA server\u0027s Server URI Array. Read the Service Level of each server to determine which server is the healthiest. Activate publishing and sampling for the data subscription on the healthiest server. Disable publishing and sampling for the data subscription on the rest of the servers. The adapter will maintain a connection to every OPC UA server in the redundancy set. However, publishing and sampling will only be active on the healthiest server. In Warm server failover, a failover occurs if the adapter loses connection to the primary server or if the primary server\u0027s Service Level drops below 200. When this occurs, the server is eligible for failover. Whenever any of the secondary servers have a higher service level than the current primary, a failover will occur. At this point, the adapter will disable publishing and sampling on the current primary server and enable them on whichever secondary server has the highest service level. This healthy server becomes the new primary. Hot If the servers in the redundancy set are operating in Hot mode, the adapter will take the following steps upon startup: Make a connection to each server defined in the primary OPC UA server\u0027s Server URI Array. Read the Service Level of each server to determine which server is the healthiest. Activate publishing and reporting for the data subscription on the healthiest server. Disable publishing and activate sampling for the data subscription on the rest of the servers. The adapter will maintain a connection to every OPC UA server in the redundancy set. However, the secondary servers will have their data subscriptions set to Sampling only. This means the data from these servers will not be sent to the adapter. Instead, it will be buffered until it becomes the primary. The size of this buffer can be configured with the MonitoredItemQueueSize property in the Client Settings configuration. Ensure that the buffer size is set to an appropriate amount so that data will not be lost during a server failover in Hot mode. In Hot server failover, a failover occurs if the adapter loses connection to the primary server or if the primary server\u0027s Service Level drops below 200. When this occurs, the server is eligible for failover. Whenever any of the secondary servers have a higher service level than the current primary, a failover will occur. At this point, the adapter will disable publishing and activate sampling on the current primary server. It will then enable publishing and reporting on whichever secondary server has the highest service level. This healthy server becomes the new primary. If the MonitoredItemQueueSize property in the Client Settings configuration is large enough to hold all of the data that occurred during the failover period, there will be no data loss. Redundancy Server Set Cache On startup, when the adapter connects to the initial primary server and reads the Server URI array, it will store the results in a json file at: Windows: %ProgramData%\\OSIsoft\\Adapters\\OpcUa\\Configuration\\\u003cComponentId\u003e_RedundantServerSet.json Linux: /usr/share/OSIsoft/Adapters/OpcUa/Configuration/\u003cComponentId\u003e_RedundantServerSet.json  usr share OSIsoft Adapters OpcUa Configuration \u003cComponentId\u003e_RedundantServerSet.json On startup, if the adapter is unable to connect to the primary server defined in the Data Source configuration, it will attempt to connect to each server in the cached server redundancy set. If the adapter is able to connect to one of the cached servers, it will then read and use the redundancy set configured on that server. The current redundancy set configuration can be found by following the steps in the Retrieve Redundant Server Set section."
                                                      },
    "content/pi-adapter-for-opc-ua-overview.html":  {
                                                        "href":  "content/pi-adapter-for-opc-ua-overview.html",
                                                        "title":  "AVEVA Adapter for OPC UA overview",
                                                        "keywords":  "AVEVA Adapter for OPC UA overview AVEVA Adapter for OPC UA is a data-collection component that transfers time-series data from source devices to OMF endpoints in AVEVA Data Hub or AVEVA Servers. OPC UA (OPC Unified Architecture) is an open standard, machine-to-machine communication protocol for industrial automation developed by the OPC Foundation. The adapter can connect to any device that uses the OPC UA communication protocol. Adapter installation You can install the adapter with a download kit that you can obtain from the OSIsoft Customer Portal. You can install the adapter on devices running either Windows or Linux operating systems. Adapter configuration Using REST API, you can configure all functions of the adapter. The configurations are stored in JSON files. For data ingress, you must define an adapter component in the system components configuration for each device to which the adapter will connect. Configuration includes information for the device and adapter component data collection. For data egress, you must specify destinations for the data, including security for the outgoing connection. Additional configurations are available to egress health and diagnostics data, add buffering configuration to protect against data loss, and record logging information for troubleshooting purposes. Once you have configured the adapter and it is sending data, you can use administration functions to manage the adapter or individual ingress components of the adapter. Health and diagnostics functions monitor the status of connected devices, adapter system functions, the number of active data streams, the rate of data ingress, the rate of errors, and the rate of data egress. EdgeCmd utility OSIsoft also provides the EdgeCmd utility, a proprietary command line tool to configure and administer an adapter on both Linux and Windows operating systems. EdgeCmd utility is installed separately from the adapter."
                                                    },
    "content/README.html":  {
                                "href":  "content/README.html",
                                "title":  "AVEVA Adapter for OPC UA",
                                "keywords":  "AVEVA Adapter for OPC UA AVEVA Adapter for OPC UA is a data-collection component that transfers time-series data from source devices to OMF (Open MessageFormat) endpoints in AVEVA Data Hub or AVEVA Servers. This repository contains the documentation for AVEVA Adapter for OPC UA. You can access a readable version of this documentation here. Subtree This documentation repository consumes the AVEVA-Adapter repository as a subtree. This repository contains a documentation framework for adapters. This subtree should be updated periodically. To update the subtree, enter the following command: git subtree pull --prefix content/main content main https://github.com/osisoft/AVEVA-Adapter https:  github.com osisoft AVEVA-Adapter main --squash License ?? 2020-2021 by OSIsoft, LLC. All rights reserved. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 http:  www.apache.org licenses LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
                            },
    "content/release-notes/release-notes.html":  {
                                                     "href":  "content/release-notes/release-notes.html",
                                                     "title":  "Release notes",
                                                     "keywords":  "Release notes For details about this release, see the following release notes: AVEVA Adapter for OPCUA AVEVA Adpater for OPCUA Module"
                                                 },
    "content/release-notes/release-notes-OPCUA.html":  {
                                                           "href":  "content/release-notes/release-notes-OPCUA.html",
                                                           "title":  "Release notes",
                                                           "keywords":  "Release notes AVEVA Adapter for OPC UA 1.4 Adapter Framework 1.7 Overview AVEVA Adapter for OPC UA collects time series data and relevant metadata from an OPC UA (OPC Unified Architecture) server and sends it to configured \"Open MessageFormat (OMF) endpoints such as PI Web API and AVEVA Data Hub. AVEVA Adapter for OPC UA can also collect health and diagnostics information. It supports buffering, unsolicited data collection, on-demand discovery of available data items on a data source, on-demand or automatic history recovery of data items, and various Windows and Linux-based operating systems as well as containerization. For more information see AVEVA Adapter for OPC UA overview . Fixes and enhancements Fixes The following issues reported from earlier versions are fixed in this release. Data collection for the OPC UA server data items will no longer be skipped when the source OPC UA Server has invalid data item attributes like: DataType, Description, BrowseName, DisplayName, UserAccessLevel. History recovery starttime and endtime supplied in local time format will be treated as a local time by the adapter node instead of the UTC time. The OpcUa Data Type \u0027UtcTime\u0027 is now supported as a DateTime type. Enhancements The following enhancements are added in this release. Reduce load on OPC UA server during history recovery by caching user access level. Enhanced logged messages to include status code in hexadecimal instead of decimal and aliased data types. Manage edge system configuration secrets in a centralized location while keeping backward compatibility. Exclude read-only facets from top level configuration in Get request. Increase the payload size to 64MB. No longer log and throw System.InvalidOperationException when the same component is added multiple times. The DeviceStatus value \"NotConfigured\" has been changed to \"Not Configured.\" Known issues There are no known issues at this time. Setup System requirements Refer to System requirements . Installation and upgrade Refer to Install the adapter . Uninstallation Refer to Uninstall the adapter . Security information and guidance OSIsoft\u0027s commitment Because the PI System often serves as a barrier protecting control system networks and mission-critical infrastructure assets, OSIsoft is committed to (1) delivering a high-quality product and (2) communicating clearly what security issues have been addressed. This release of AVEVA Adapter for OPC UA is the highest quality and most secure version of the AVEVA Adapter for OPC UA released to date. OSIsoft\u0027s commitment to improving the PI System is ongoing, and each future version should raise the quality and security bar even further. Vulnerability communication The practice of publicly disclosing internally discovered vulnerabilities is consistent with the Common Industrial Control System Vulnerability Disclosure Framework developed by the Industrial Control Systems Joint Working Group (ICSJWG) . Despite the increased risk posed by greater transparency, OSIsoft is sharing this information to help you make an informed decision about when to upgrade to ensure your PI System has the best available protection. For more information, refer to OSIsoft\u0027s Ethical Disclosure Policy . To report a security vulnerability, refer to OSIsoft\u0027s Report a Security Vulnerability . Vulnerability scoring OSIsoft has selected the Common Vulnerability Scoring System (CVSS) to quantify the severity of security vulnerabilities for disclosure. To calculate the CVSS scores, OSIsoft uses the National Vulnerability Database (NVD) calculator maintained by the National Institute of Standards and Technology (NIST). OSIsoft uses Critical, High, Medium and Low categories to aggregate the CVSS Base scores. This removes some of the opinion-related errors of CVSS scoring. As noted in the CVSS specification , Base scores range from 0 for the lowest severity to 10 for the highest severity. Overview of new vulnerabilities found or fixed This section is intended to provide relevant security-related information to guide your installation or upgrade decision. OSIsoft is proactively disclosing aggregate information about the number and severity of AVEVA Adapter for OPC UA security vulnerabilities that are fixed in this release. Component Version CVE or Reference CVSS Mitigation zlib 1.2.11 CVE-2018-25032 7.5 The AVEVA Adapter???s utilization of zlib through the .NET 6 Framework does not expose these vulnerabilities zlib 1.2.11 BSDA-2018-5271 7.1 The AVEVA Adapter???s utilization of zlib through the .NET 6 Framework does not expose these vulnerabilities. zlib 1.2.11 CVE-2022-37434 9.3 The AVEVA Adapter???s utilization of zlib through the .NET 6 Framework does not expose these vulnerabilities. Documentation overview EdgeCmd utility : Provides an overview on how to configure and administer AVEVA Adapters on Linux and Windows using command line arguments. Technical support and resources Refer to Technical support and feedback ."
                                                       },
    "content/release-notes/release-notes-OPCUA-module.html":  {
                                                                  "href":  "content/release-notes/release-notes-OPCUA-module.html",
                                                                  "title":  "Release notes",
                                                                  "keywords":  "Release notes AVEVA Adapter for OPC UA 1.4 Adapter Framework 1.7 Overview AVEVA Adapter for OPC UA collects time series data and relevant metadata from an OPC UA (OPC Unified Architecture) server and sends it to configured \"Open MessageFormat (OMF) endpoints such as PI Web API and AVEVA Data Hub. AVEVA Adapter for OPC UA can also collect health and diagnostics information. It supports buffering, unsolicited data collection, on-demand discovery of available data items on a data source, on-demand or automatic history recovery of data items, and various Windows and Linux-based operating systems as well as containerization. For more information see AVEVA Adapter for OPC UA overview . Fixes and enhancements Fixes The following issues reported from earlier versions are fixed in this release. Data collection for the OPC UA server data items will no longer be skipped when the source OPC UA Server has invalid data item attributes like: DataType, Description, BrowseName, DisplayName, UserAccessLevel. History recovery starttime and endtime supplied in local time format will be treated as a local time by the adapter node instead of the UTC time. The OpcUa Data Type \u0027UtcTime\u0027 is now supported as a DateTime type. Enhancements The following enhancements are added in this release. Reduce load on OPC UA server during history recovery by caching user access level. Enhanced logged messages to include status code in hexadecimal instead of decimal and aliased data types. Manage edge system configuration secrets in a centralized location while keeping backward compatibility. Exclude read-only facets from top level configuration in Get request. Increase the payload size to 64MB. No longer log and throw System.InvalidOperationException when the same component is added multiple times. The DeviceStatus value \"NotConfigured\" has been changed to \"Not Configured.\" Known issues There are no known issues at this time. Setup System requirements Refer to System requirements . Installation and upgrade Refer to Install the adapter . Uninstallation Refer to Uninstall the adapter . Security information and guidance OSIsoft\u0027s commitment Because the PI System often serves as a barrier protecting control system networks and mission-critical infrastructure assets, OSIsoft is committed to (1) delivering a high-quality product and (2) communicating clearly what security issues have been addressed. This release of AVEVA Adapter for OPC UA is the highest quality and most secure version of the AVEVA Adapter for OPC UA released to date. OSIsoft\u0027s commitment to improving the PI System is ongoing, and each future version should raise the quality and security bar even further. Vulnerability communication The practice of publicly disclosing internally discovered vulnerabilities is consistent with the Common Industrial Control System Vulnerability Disclosure Framework developed by the Industrial Control Systems Joint Working Group (ICSJWG) . Despite the increased risk posed by greater transparency, OSIsoft is sharing this information to help you make an informed decision about when to upgrade to ensure your PI System has the best available protection. For more information, refer to OSIsoft\u0027s Ethical Disclosure Policy . To report a security vulnerability, refer to OSIsoft\u0027s Report a Security Vulnerability . Vulnerability scoring OSIsoft has selected the Common Vulnerability Scoring System (CVSS) to quantify the severity of security vulnerabilities for disclosure. To calculate the CVSS scores, OSIsoft uses the National Vulnerability Database (NVD) calculator maintained by the National Institute of Standards and Technology (NIST). OSIsoft uses Critical, High, Medium and Low categories to aggregate the CVSS Base scores. This removes some of the opinion-related errors of CVSS scoring. As noted in the CVSS specification , Base scores range from 0 for the lowest severity to 10 for the highest severity. Overview of new vulnerabilities found or fixed This section is intended to provide relevant security-related information to guide your installation or upgrade decision. OSIsoft is proactively disclosing aggregate information about the number and severity of AVEVA Adapter for OPC UA security vulnerabilities that are fixed in this release. Component Version CVE or Reference CVSS Mitigation zlib 1.2.11 CVE-2018-25032 7.5 The AVEVA Adapter???s utilization of zlib through the .NET 6 Framework does not expose these vulnerabilities zlib 1.2.11 BSDA-2018-5271 7.1 The AVEVA Adapter???s utilization of zlib through the .NET 6 Framework does not expose these vulnerabilities. zlib 1.2.11 CVE-2022-37434 9.3 The AVEVA Adapter???s utilization of zlib through the .NET 6 Framework does not expose these vulnerabilities. Documentation overview EdgeCmd utility : Provides an overview on how to configure and administer AVEVA Adapters on Linux and Windows using command line arguments. Technical support and resources Refer to Technical support and feedback ."
                                                              },
    "content/troubleshooting/troubleshoot-pi-adapter-for-opc-ua.html":  {
                                                                            "href":  "content/troubleshooting/troubleshoot-pi-adapter-for-opc-ua.html",
                                                                            "title":  "Troubleshoot AVEVA Adapter for OPC UA",
                                                                            "keywords":  "Troubleshoot AVEVA Adapter for OPC UA To troubleshoot issues with AVEVA Adapter for OPC UA, you should check the adapter\u0027s configuration, connectivity, and logs, as detailed in the following sections. If you are unable to resolve issues with the adapter or need additional guidance, contact OSIsoft Technical Support. Check configurations In the data source configuration , verify that the configured EndpointURL and, if specified, the UserName and Password are correct. Verify that OPC UA server trusts AVEVA Adapter\u0027s certificate and vice versa. In the data selection configuration , verify that each configured data selection item below is correct. NodeId - Verify that the referenced nodeId exists on the server. DataFilterId - If configured, verify that the referenced data filter exists. In the egress endpoints configuration , verify that each configured endpoint\u0027s Endpoint property and credentials are correct. For a AVEVA Server or EDS endpoint, verify UserName and Password . For a AVEVA Server endpoint, verify UserName and Password . For an AVEVA Data Hub endpoint, verify ClientId and ClientSecret . Check connectivity Verify there are active connections to the data source and egress endpoints. If you configured a health endpoint, use it to determine the status of the adapter.For more information, see Health and diagnostics . Check logs Check the adapter and endpoint logs to isolate issues. Optional : Change the log level of the adapter to receive additional information and context.For more information, see Logging configuration ."
                                                                        },
    "README.html":  {
                        "href":  "README.html",
                        "title":  "AVEVA Adapter for OPC UA",
                        "keywords":  "AVEVA Adapter for OPC UA AVEVA Adapter for OPC UA is a data-collection component that transfers time-series data from source devices to OMF (Open Message Format) endpoints in AVEVA Data Hub or AVEVA Servers. This repository contains the documentation for AVEVA Adapter for OPC UA. You can access a readable version of this documentation here. License ?? 2019 - 2023 OSIsoft, LLC. All rights reserved. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 http:  www.apache.org licenses LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
                    }
}
